{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting different exploration strategies\n",
    "By adjusting action noise (sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "\n",
      "=== Training with Ïƒ = 0.05 ===\n",
      "Logging to ./aqua_tensorboard/sigma_0.05\\TD3_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yigal Lim\\AppData\\Roaming\\Python\\Python312\\site-packages\\stable_baselines3\\common\\env_checker.py:462: UserWarning: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) cf. https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 47       |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 95       |\n",
      "|    time_elapsed    | 7        |\n",
      "|    total_timesteps | 720      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.09    |\n",
      "|    critic_loss     | 0.148    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 619      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 17.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 91       |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 1440     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.36    |\n",
      "|    critic_loss     | 0.329    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1339     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 49.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 24       |\n",
      "|    total_timesteps | 2160     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.46    |\n",
      "|    critic_loss     | 0.791    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2059     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 53       |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 32       |\n",
      "|    total_timesteps | 2880     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.91    |\n",
      "|    critic_loss     | 1.97     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2779     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 70.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 41       |\n",
      "|    total_timesteps | 3600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.11    |\n",
      "|    critic_loss     | 1.21     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 3499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 85.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 50       |\n",
      "|    total_timesteps | 4320     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.18    |\n",
      "|    critic_loss     | 1.16     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 4219     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 95.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 58       |\n",
      "|    total_timesteps | 5040     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -10.6    |\n",
      "|    critic_loss     | 3.45     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 4939     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 99.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 86       |\n",
      "|    time_elapsed    | 66       |\n",
      "|    total_timesteps | 5760     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.6    |\n",
      "|    critic_loss     | 1.5      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 5659     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 103      |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 75       |\n",
      "|    total_timesteps | 6480     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.1    |\n",
      "|    critic_loss     | 1.37     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 6379     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 106      |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 84       |\n",
      "|    total_timesteps | 7200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.7    |\n",
      "|    critic_loss     | 2.23     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 7099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 108      |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 92       |\n",
      "|    total_timesteps | 7920     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.1    |\n",
      "|    critic_loss     | 1.54     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 7819     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 110      |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 101      |\n",
      "|    total_timesteps | 8640     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.7    |\n",
      "|    critic_loss     | 2.18     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 8539     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 112      |\n",
      "| time/              |          |\n",
      "|    episodes        | 52       |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 110      |\n",
      "|    total_timesteps | 9360     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.9    |\n",
      "|    critic_loss     | 2.81     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 9259     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 113      |\n",
      "| time/              |          |\n",
      "|    episodes        | 56       |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 119      |\n",
      "|    total_timesteps | 10080    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.1    |\n",
      "|    critic_loss     | 1.96     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 9979     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 114      |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 127      |\n",
      "|    total_timesteps | 10800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.4    |\n",
      "|    critic_loss     | 3.54     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 10699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 116      |\n",
      "| time/              |          |\n",
      "|    episodes        | 64       |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 135      |\n",
      "|    total_timesteps | 11520    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.1    |\n",
      "|    critic_loss     | 1.35     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 11419    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 116      |\n",
      "| time/              |          |\n",
      "|    episodes        | 68       |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 145      |\n",
      "|    total_timesteps | 12240    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.8    |\n",
      "|    critic_loss     | 7.18     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 12139    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 118      |\n",
      "| time/              |          |\n",
      "|    episodes        | 72       |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 153      |\n",
      "|    total_timesteps | 12960    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17      |\n",
      "|    critic_loss     | 2.18     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 12859    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 119      |\n",
      "| time/              |          |\n",
      "|    episodes        | 76       |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 162      |\n",
      "|    total_timesteps | 13680    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.9    |\n",
      "|    critic_loss     | 2.84     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 13579    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 118      |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 170      |\n",
      "|    total_timesteps | 14400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -18.2    |\n",
      "|    critic_loss     | 8.86     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 14299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 115      |\n",
      "| time/              |          |\n",
      "|    episodes        | 84       |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 179      |\n",
      "|    total_timesteps | 15120    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17      |\n",
      "|    critic_loss     | 2.64     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 15019    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 114      |\n",
      "| time/              |          |\n",
      "|    episodes        | 88       |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 188      |\n",
      "|    total_timesteps | 15840    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.7    |\n",
      "|    critic_loss     | 2.44     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 15739    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 113      |\n",
      "| time/              |          |\n",
      "|    episodes        | 92       |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 196      |\n",
      "|    total_timesteps | 16560    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.4    |\n",
      "|    critic_loss     | 3.1      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 16459    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 112      |\n",
      "| time/              |          |\n",
      "|    episodes        | 96       |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 205      |\n",
      "|    total_timesteps | 17280    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.7    |\n",
      "|    critic_loss     | 2.88     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 17179    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 111      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 213      |\n",
      "|    total_timesteps | 18000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.2    |\n",
      "|    critic_loss     | 3.25     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 17899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 114      |\n",
      "| time/              |          |\n",
      "|    episodes        | 104      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 222      |\n",
      "|    total_timesteps | 18720    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.1    |\n",
      "|    critic_loss     | 2.96     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 18619    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 118      |\n",
      "| time/              |          |\n",
      "|    episodes        | 108      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 230      |\n",
      "|    total_timesteps | 19440    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -20.5    |\n",
      "|    critic_loss     | 3.23     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 19339    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 113      |\n",
      "| time/              |          |\n",
      "|    episodes        | 112      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 238      |\n",
      "|    total_timesteps | 20160    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -18.3    |\n",
      "|    critic_loss     | 3.02     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 20059    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 110      |\n",
      "| time/              |          |\n",
      "|    episodes        | 116      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 246      |\n",
      "|    total_timesteps | 20880    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -21      |\n",
      "|    critic_loss     | 2.38     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 20779    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 104      |\n",
      "| time/              |          |\n",
      "|    episodes        | 120      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 255      |\n",
      "|    total_timesteps | 21600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -19.3    |\n",
      "|    critic_loss     | 1.51     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 21499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 97.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 124      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 263      |\n",
      "|    total_timesteps | 22320    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -18.3    |\n",
      "|    critic_loss     | 2.32     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 22219    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 91.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 128      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 271      |\n",
      "|    total_timesteps | 23040    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.5    |\n",
      "|    critic_loss     | 1.07     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 22939    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 85.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 132      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 279      |\n",
      "|    total_timesteps | 23760    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.1    |\n",
      "|    critic_loss     | 3.08     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 23659    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 80.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 136      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 288      |\n",
      "|    total_timesteps | 24480    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.9    |\n",
      "|    critic_loss     | 0.447    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 24379    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 74.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 140      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 296      |\n",
      "|    total_timesteps | 25200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.3    |\n",
      "|    critic_loss     | 6.07     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 25099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 69.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 144      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 304      |\n",
      "|    total_timesteps | 25920    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.3    |\n",
      "|    critic_loss     | 1.32     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 25819    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 63.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 148      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 312      |\n",
      "|    total_timesteps | 26640    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13.4    |\n",
      "|    critic_loss     | 4.22     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 26539    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 57.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 152      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 320      |\n",
      "|    total_timesteps | 27360    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13.2    |\n",
      "|    critic_loss     | 1.43     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 27259    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 52.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 156      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 328      |\n",
      "|    total_timesteps | 28080    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.1    |\n",
      "|    critic_loss     | 0.87     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 27979    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 46.7     |\n",
      "| time/              |          |\n",
      "|    episodes        | 160      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 338      |\n",
      "|    total_timesteps | 28800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.4    |\n",
      "|    critic_loss     | 0.841    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 28699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 41       |\n",
      "| time/              |          |\n",
      "|    episodes        | 164      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 346      |\n",
      "|    total_timesteps | 29520    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -10.7    |\n",
      "|    critic_loss     | 0.322    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 29419    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 35.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 168      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 354      |\n",
      "|    total_timesteps | 30240    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.96    |\n",
      "|    critic_loss     | 0.286    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 30139    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 29.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 172      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 363      |\n",
      "|    total_timesteps | 30960    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.32    |\n",
      "|    critic_loss     | 0.806    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 30859    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 23.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 176      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 371      |\n",
      "|    total_timesteps | 31680    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.58    |\n",
      "|    critic_loss     | 0.552    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 31579    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 18.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 180      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 379      |\n",
      "|    total_timesteps | 32400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.29    |\n",
      "|    critic_loss     | 0.724    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 32299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 16.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 184      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 387      |\n",
      "|    total_timesteps | 33120    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.68    |\n",
      "|    critic_loss     | 0.642    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 33019    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 12.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 188      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 396      |\n",
      "|    total_timesteps | 33840    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.01    |\n",
      "|    critic_loss     | 0.388    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 33739    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 8.58     |\n",
      "| time/              |          |\n",
      "|    episodes        | 192      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 405      |\n",
      "|    total_timesteps | 34560    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.68    |\n",
      "|    critic_loss     | 0.231    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 34459    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 4.33     |\n",
      "| time/              |          |\n",
      "|    episodes        | 196      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 414      |\n",
      "|    total_timesteps | 35280    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.43    |\n",
      "|    critic_loss     | 0.397    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 35179    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 0.252    |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 423      |\n",
      "|    total_timesteps | 36000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.99    |\n",
      "|    critic_loss     | 0.532    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 35899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | -4.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 204      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 432      |\n",
      "|    total_timesteps | 36720    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.66    |\n",
      "|    critic_loss     | 0.373    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 36619    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | -8.34    |\n",
      "| time/              |          |\n",
      "|    episodes        | 208      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 440      |\n",
      "|    total_timesteps | 37440    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.16    |\n",
      "|    critic_loss     | 0.353    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 37339    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | -8.53    |\n",
      "| time/              |          |\n",
      "|    episodes        | 212      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 448      |\n",
      "|    total_timesteps | 38160    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.86    |\n",
      "|    critic_loss     | 0.535    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 38059    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | -8.62    |\n",
      "| time/              |          |\n",
      "|    episodes        | 216      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 458      |\n",
      "|    total_timesteps | 38880    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.45    |\n",
      "|    critic_loss     | 0.593    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 38779    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | -8.68    |\n",
      "| time/              |          |\n",
      "|    episodes        | 220      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 467      |\n",
      "|    total_timesteps | 39600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.13    |\n",
      "|    critic_loss     | 0.0833   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 39499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | -8.83    |\n",
      "| time/              |          |\n",
      "|    episodes        | 224      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 478      |\n",
      "|    total_timesteps | 40320    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.8     |\n",
      "|    critic_loss     | 0.482    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 40219    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | -8.94    |\n",
      "| time/              |          |\n",
      "|    episodes        | 228      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 487      |\n",
      "|    total_timesteps | 41040    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.53    |\n",
      "|    critic_loss     | 0.269    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 40939    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | -8.97    |\n",
      "| time/              |          |\n",
      "|    episodes        | 232      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 496      |\n",
      "|    total_timesteps | 41760    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.52    |\n",
      "|    critic_loss     | 0.3      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 41659    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | -8.89    |\n",
      "| time/              |          |\n",
      "|    episodes        | 236      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 505      |\n",
      "|    total_timesteps | 42480    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.15    |\n",
      "|    critic_loss     | 0.12     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 42379    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | -8.73    |\n",
      "| time/              |          |\n",
      "|    episodes        | 240      |\n",
      "|    fps             | 83       |\n",
      "|    time_elapsed    | 515      |\n",
      "|    total_timesteps | 43200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.02    |\n",
      "|    critic_loss     | 0.114    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 43099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | -8.49    |\n",
      "| time/              |          |\n",
      "|    episodes        | 244      |\n",
      "|    fps             | 83       |\n",
      "|    time_elapsed    | 524      |\n",
      "|    total_timesteps | 43920    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.82    |\n",
      "|    critic_loss     | 0.161    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 43819    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | -8.23    |\n",
      "| time/              |          |\n",
      "|    episodes        | 248      |\n",
      "|    fps             | 83       |\n",
      "|    time_elapsed    | 532      |\n",
      "|    total_timesteps | 44640    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.72    |\n",
      "|    critic_loss     | 0.146    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 44539    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | -8.02    |\n",
      "| time/              |          |\n",
      "|    episodes        | 252      |\n",
      "|    fps             | 83       |\n",
      "|    time_elapsed    | 540      |\n",
      "|    total_timesteps | 45360    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.81    |\n",
      "|    critic_loss     | 0.0708   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 45259    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | -7.91    |\n",
      "| time/              |          |\n",
      "|    episodes        | 256      |\n",
      "|    fps             | 83       |\n",
      "|    time_elapsed    | 549      |\n",
      "|    total_timesteps | 46080    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.59    |\n",
      "|    critic_loss     | 0.152    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 45979    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | -7.77    |\n",
      "| time/              |          |\n",
      "|    episodes        | 260      |\n",
      "|    fps             | 83       |\n",
      "|    time_elapsed    | 557      |\n",
      "|    total_timesteps | 46800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.53    |\n",
      "|    critic_loss     | 0.0804   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 46699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | -7.63    |\n",
      "| time/              |          |\n",
      "|    episodes        | 264      |\n",
      "|    fps             | 83       |\n",
      "|    time_elapsed    | 566      |\n",
      "|    total_timesteps | 47520    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.49    |\n",
      "|    critic_loss     | 0.0451   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 47419    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | -7.49    |\n",
      "| time/              |          |\n",
      "|    episodes        | 268      |\n",
      "|    fps             | 83       |\n",
      "|    time_elapsed    | 574      |\n",
      "|    total_timesteps | 48240    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.37    |\n",
      "|    critic_loss     | 0.0509   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 48139    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | -7.35    |\n",
      "| time/              |          |\n",
      "|    episodes        | 272      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 582      |\n",
      "|    total_timesteps | 48960    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.2     |\n",
      "|    critic_loss     | 0.117    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 48859    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | -7.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 276      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 589      |\n",
      "|    total_timesteps | 49680    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.2     |\n",
      "|    critic_loss     | 0.0883   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 49579    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | -7.06    |\n",
      "| time/              |          |\n",
      "|    episodes        | 280      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 598      |\n",
      "|    total_timesteps | 50400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.02    |\n",
      "|    critic_loss     | 0.0823   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 50299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | -6.96    |\n",
      "| time/              |          |\n",
      "|    episodes        | 284      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 607      |\n",
      "|    total_timesteps | 51120    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.33    |\n",
      "|    critic_loss     | 0.051    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 51019    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | -6.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 288      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 616      |\n",
      "|    total_timesteps | 51840    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.01    |\n",
      "|    critic_loss     | 0.0201   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 51739    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | -6.83    |\n",
      "| time/              |          |\n",
      "|    episodes        | 292      |\n",
      "|    fps             | 83       |\n",
      "|    time_elapsed    | 625      |\n",
      "|    total_timesteps | 52560    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.93    |\n",
      "|    critic_loss     | 0.0589   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 52459    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | -6.74    |\n",
      "| time/              |          |\n",
      "|    episodes        | 296      |\n",
      "|    fps             | 83       |\n",
      "|    time_elapsed    | 635      |\n",
      "|    total_timesteps | 53280    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.85    |\n",
      "|    critic_loss     | 0.0397   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 53179    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | -5.61    |\n",
      "| time/              |          |\n",
      "|    episodes        | 300      |\n",
      "|    fps             | 83       |\n",
      "|    time_elapsed    | 645      |\n",
      "|    total_timesteps | 54000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.73    |\n",
      "|    critic_loss     | 0.0651   |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 53899    |\n",
      "---------------------------------\n",
      "âœ… Training curve saved to: td3_rewards_sigma_0.05.png\n",
      "ðŸ“Š Total reward: 10606.54\n",
      "ðŸ“‰ Reward variation (std dev): 62.94\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "\n",
      "=== Training with Ïƒ = 0.10 ===\n",
      "Logging to ./aqua_tensorboard/sigma_0.10\\TD3_3\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 46.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 8        |\n",
      "|    total_timesteps | 720      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.2     |\n",
      "|    critic_loss     | 0.377    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 619      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 63       |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 79       |\n",
      "|    time_elapsed    | 18       |\n",
      "|    total_timesteps | 1440     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.02    |\n",
      "|    critic_loss     | 0.389    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1339     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 88.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 78       |\n",
      "|    time_elapsed    | 27       |\n",
      "|    total_timesteps | 2160     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.73    |\n",
      "|    critic_loss     | 1.27     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2059     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 102      |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 77       |\n",
      "|    time_elapsed    | 37       |\n",
      "|    total_timesteps | 2880     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.21    |\n",
      "|    critic_loss     | 0.989    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2779     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 106      |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 77       |\n",
      "|    time_elapsed    | 46       |\n",
      "|    total_timesteps | 3600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9       |\n",
      "|    critic_loss     | 1.76     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 3499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 110      |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 76       |\n",
      "|    time_elapsed    | 56       |\n",
      "|    total_timesteps | 4320     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.2    |\n",
      "|    critic_loss     | 1.59     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 4219     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 112      |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 76       |\n",
      "|    time_elapsed    | 66       |\n",
      "|    total_timesteps | 5040     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.8    |\n",
      "|    critic_loss     | 1.12     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 4939     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 113      |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 77       |\n",
      "|    time_elapsed    | 74       |\n",
      "|    total_timesteps | 5760     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.6    |\n",
      "|    critic_loss     | 2.04     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 5659     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 114      |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 77       |\n",
      "|    time_elapsed    | 83       |\n",
      "|    total_timesteps | 6480     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13      |\n",
      "|    critic_loss     | 1.69     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 6379     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 111      |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 78       |\n",
      "|    time_elapsed    | 91       |\n",
      "|    total_timesteps | 7200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.5    |\n",
      "|    critic_loss     | 3.09     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 7099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 113      |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 79       |\n",
      "|    time_elapsed    | 99       |\n",
      "|    total_timesteps | 7920     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.9    |\n",
      "|    critic_loss     | 2.24     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 7819     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 116      |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 80       |\n",
      "|    time_elapsed    | 107      |\n",
      "|    total_timesteps | 8640     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.7    |\n",
      "|    critic_loss     | 3.08     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 8539     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 119      |\n",
      "| time/              |          |\n",
      "|    episodes        | 52       |\n",
      "|    fps             | 80       |\n",
      "|    time_elapsed    | 115      |\n",
      "|    total_timesteps | 9360     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.6    |\n",
      "|    critic_loss     | 2.34     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 9259     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 122      |\n",
      "| time/              |          |\n",
      "|    episodes        | 56       |\n",
      "|    fps             | 81       |\n",
      "|    time_elapsed    | 123      |\n",
      "|    total_timesteps | 10080    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -18.4    |\n",
      "|    critic_loss     | 2.14     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 9979     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 124      |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 81       |\n",
      "|    time_elapsed    | 133      |\n",
      "|    total_timesteps | 10800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -18.3    |\n",
      "|    critic_loss     | 1.51     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 10699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 123      |\n",
      "| time/              |          |\n",
      "|    episodes        | 64       |\n",
      "|    fps             | 81       |\n",
      "|    time_elapsed    | 141      |\n",
      "|    total_timesteps | 11520    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -18.6    |\n",
      "|    critic_loss     | 2.19     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 11419    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 122      |\n",
      "| time/              |          |\n",
      "|    episodes        | 68       |\n",
      "|    fps             | 81       |\n",
      "|    time_elapsed    | 150      |\n",
      "|    total_timesteps | 12240    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -21.9    |\n",
      "|    critic_loss     | 5.57     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 12139    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 123      |\n",
      "| time/              |          |\n",
      "|    episodes        | 72       |\n",
      "|    fps             | 81       |\n",
      "|    time_elapsed    | 158      |\n",
      "|    total_timesteps | 12960    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -22      |\n",
      "|    critic_loss     | 8.65     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 12859    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 124      |\n",
      "| time/              |          |\n",
      "|    episodes        | 76       |\n",
      "|    fps             | 82       |\n",
      "|    time_elapsed    | 166      |\n",
      "|    total_timesteps | 13680    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -23.5    |\n",
      "|    critic_loss     | 7.96     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 13579    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 125      |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 82       |\n",
      "|    time_elapsed    | 174      |\n",
      "|    total_timesteps | 14400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -21.6    |\n",
      "|    critic_loss     | 4.38     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 14299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 126      |\n",
      "| time/              |          |\n",
      "|    episodes        | 84       |\n",
      "|    fps             | 82       |\n",
      "|    time_elapsed    | 182      |\n",
      "|    total_timesteps | 15120    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -22.4    |\n",
      "|    critic_loss     | 3.95     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 15019    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 127      |\n",
      "| time/              |          |\n",
      "|    episodes        | 88       |\n",
      "|    fps             | 83       |\n",
      "|    time_elapsed    | 190      |\n",
      "|    total_timesteps | 15840    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -22.6    |\n",
      "|    critic_loss     | 4.64     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 15739    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 129      |\n",
      "| time/              |          |\n",
      "|    episodes        | 92       |\n",
      "|    fps             | 83       |\n",
      "|    time_elapsed    | 198      |\n",
      "|    total_timesteps | 16560    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -24.2    |\n",
      "|    critic_loss     | 5.13     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 16459    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 129      |\n",
      "| time/              |          |\n",
      "|    episodes        | 96       |\n",
      "|    fps             | 83       |\n",
      "|    time_elapsed    | 206      |\n",
      "|    total_timesteps | 17280    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -23      |\n",
      "|    critic_loss     | 3.91     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 17179    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 130      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 83       |\n",
      "|    time_elapsed    | 215      |\n",
      "|    total_timesteps | 18000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -22.8    |\n",
      "|    critic_loss     | 3.74     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 17899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 134      |\n",
      "| time/              |          |\n",
      "|    episodes        | 104      |\n",
      "|    fps             | 83       |\n",
      "|    time_elapsed    | 223      |\n",
      "|    total_timesteps | 18720    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -23.9    |\n",
      "|    critic_loss     | 4.62     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 18619    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 137      |\n",
      "| time/              |          |\n",
      "|    episodes        | 108      |\n",
      "|    fps             | 83       |\n",
      "|    time_elapsed    | 231      |\n",
      "|    total_timesteps | 19440    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -23.4    |\n",
      "|    critic_loss     | 4.04     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 19339    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 134      |\n",
      "| time/              |          |\n",
      "|    episodes        | 112      |\n",
      "|    fps             | 83       |\n",
      "|    time_elapsed    | 240      |\n",
      "|    total_timesteps | 20160    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -23.5    |\n",
      "|    critic_loss     | 6.57     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 20059    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 129      |\n",
      "| time/              |          |\n",
      "|    episodes        | 116      |\n",
      "|    fps             | 83       |\n",
      "|    time_elapsed    | 248      |\n",
      "|    total_timesteps | 20880    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -24.4    |\n",
      "|    critic_loss     | 5.91     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 20779    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 128      |\n",
      "| time/              |          |\n",
      "|    episodes        | 120      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 257      |\n",
      "|    total_timesteps | 21600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -24.5    |\n",
      "|    critic_loss     | 6.81     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 21499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 128      |\n",
      "| time/              |          |\n",
      "|    episodes        | 124      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 265      |\n",
      "|    total_timesteps | 22320    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -24.4    |\n",
      "|    critic_loss     | 4.57     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 22219    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 128      |\n",
      "| time/              |          |\n",
      "|    episodes        | 128      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 273      |\n",
      "|    total_timesteps | 23040    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -26.2    |\n",
      "|    critic_loss     | 2.74     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 22939    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 127      |\n",
      "| time/              |          |\n",
      "|    episodes        | 132      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 281      |\n",
      "|    total_timesteps | 23760    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -23.2    |\n",
      "|    critic_loss     | 4.02     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 23659    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 128      |\n",
      "| time/              |          |\n",
      "|    episodes        | 136      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 288      |\n",
      "|    total_timesteps | 24480    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -25.1    |\n",
      "|    critic_loss     | 4.1      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 24379    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 130      |\n",
      "| time/              |          |\n",
      "|    episodes        | 140      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 297      |\n",
      "|    total_timesteps | 25200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -24.5    |\n",
      "|    critic_loss     | 4.01     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 25099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 131      |\n",
      "| time/              |          |\n",
      "|    episodes        | 144      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 306      |\n",
      "|    total_timesteps | 25920    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -23.7    |\n",
      "|    critic_loss     | 2.36     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 25819    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 131      |\n",
      "| time/              |          |\n",
      "|    episodes        | 148      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 315      |\n",
      "|    total_timesteps | 26640    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -24.8    |\n",
      "|    critic_loss     | 2.1      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 26539    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 130      |\n",
      "| time/              |          |\n",
      "|    episodes        | 152      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 323      |\n",
      "|    total_timesteps | 27360    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -24      |\n",
      "|    critic_loss     | 3.35     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 27259    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 129      |\n",
      "| time/              |          |\n",
      "|    episodes        | 156      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 332      |\n",
      "|    total_timesteps | 28080    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -25.9    |\n",
      "|    critic_loss     | 3.1      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 27979    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 129      |\n",
      "| time/              |          |\n",
      "|    episodes        | 160      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 340      |\n",
      "|    total_timesteps | 28800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -25.2    |\n",
      "|    critic_loss     | 4.08     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 28699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 129      |\n",
      "| time/              |          |\n",
      "|    episodes        | 164      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 348      |\n",
      "|    total_timesteps | 29520    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -24.9    |\n",
      "|    critic_loss     | 2.95     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 29419    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 131      |\n",
      "| time/              |          |\n",
      "|    episodes        | 168      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 357      |\n",
      "|    total_timesteps | 30240    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -23.5    |\n",
      "|    critic_loss     | 3.55     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 30139    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 130      |\n",
      "| time/              |          |\n",
      "|    episodes        | 172      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 365      |\n",
      "|    total_timesteps | 30960    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -25.7    |\n",
      "|    critic_loss     | 6.31     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 30859    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 128      |\n",
      "| time/              |          |\n",
      "|    episodes        | 176      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 374      |\n",
      "|    total_timesteps | 31680    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -25.6    |\n",
      "|    critic_loss     | 5.63     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 31579    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 127      |\n",
      "| time/              |          |\n",
      "|    episodes        | 180      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 382      |\n",
      "|    total_timesteps | 32400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -24.4    |\n",
      "|    critic_loss     | 5.7      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 32299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 126      |\n",
      "| time/              |          |\n",
      "|    episodes        | 184      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 390      |\n",
      "|    total_timesteps | 33120    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -25.1    |\n",
      "|    critic_loss     | 4.51     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 33019    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 126      |\n",
      "| time/              |          |\n",
      "|    episodes        | 188      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 398      |\n",
      "|    total_timesteps | 33840    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -23.8    |\n",
      "|    critic_loss     | 3.27     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 33739    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 125      |\n",
      "| time/              |          |\n",
      "|    episodes        | 192      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 407      |\n",
      "|    total_timesteps | 34560    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -21.8    |\n",
      "|    critic_loss     | 3.78     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 34459    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 124      |\n",
      "| time/              |          |\n",
      "|    episodes        | 196      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 415      |\n",
      "|    total_timesteps | 35280    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -24.9    |\n",
      "|    critic_loss     | 5.59     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 35179    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 124      |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 423      |\n",
      "|    total_timesteps | 36000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -23.6    |\n",
      "|    critic_loss     | 5.49     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 35899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 123      |\n",
      "| time/              |          |\n",
      "|    episodes        | 204      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 433      |\n",
      "|    total_timesteps | 36720    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -26.7    |\n",
      "|    critic_loss     | 4.47     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 36619    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 123      |\n",
      "| time/              |          |\n",
      "|    episodes        | 208      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 441      |\n",
      "|    total_timesteps | 37440    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -22.6    |\n",
      "|    critic_loss     | 3        |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 37339    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 126      |\n",
      "| time/              |          |\n",
      "|    episodes        | 212      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 450      |\n",
      "|    total_timesteps | 38160    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -22.6    |\n",
      "|    critic_loss     | 3.79     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 38059    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 131      |\n",
      "| time/              |          |\n",
      "|    episodes        | 216      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 458      |\n",
      "|    total_timesteps | 38880    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -23      |\n",
      "|    critic_loss     | 3.52     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 38779    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 133      |\n",
      "| time/              |          |\n",
      "|    episodes        | 220      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 466      |\n",
      "|    total_timesteps | 39600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -24.2    |\n",
      "|    critic_loss     | 5.65     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 39499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 134      |\n",
      "| time/              |          |\n",
      "|    episodes        | 224      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 475      |\n",
      "|    total_timesteps | 40320    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -25.7    |\n",
      "|    critic_loss     | 3.45     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 40219    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 135      |\n",
      "| time/              |          |\n",
      "|    episodes        | 228      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 483      |\n",
      "|    total_timesteps | 41040    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -24.6    |\n",
      "|    critic_loss     | 2.12     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 40939    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 135      |\n",
      "| time/              |          |\n",
      "|    episodes        | 232      |\n",
      "|    fps             | 84       |\n",
      "|    time_elapsed    | 491      |\n",
      "|    total_timesteps | 41760    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -24.1    |\n",
      "|    critic_loss     | 4.23     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 41659    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 136      |\n",
      "| time/              |          |\n",
      "|    episodes        | 236      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 499      |\n",
      "|    total_timesteps | 42480    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -24.3    |\n",
      "|    critic_loss     | 3.71     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 42379    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 137      |\n",
      "| time/              |          |\n",
      "|    episodes        | 240      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 507      |\n",
      "|    total_timesteps | 43200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -24.1    |\n",
      "|    critic_loss     | 3.33     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 43099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 137      |\n",
      "| time/              |          |\n",
      "|    episodes        | 244      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 516      |\n",
      "|    total_timesteps | 43920    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -25.4    |\n",
      "|    critic_loss     | 2.49     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 43819    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 138      |\n",
      "| time/              |          |\n",
      "|    episodes        | 248      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 524      |\n",
      "|    total_timesteps | 44640    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -25.1    |\n",
      "|    critic_loss     | 2.03     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 44539    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 139      |\n",
      "| time/              |          |\n",
      "|    episodes        | 252      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 532      |\n",
      "|    total_timesteps | 45360    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -23.5    |\n",
      "|    critic_loss     | 2.26     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 45259    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 140      |\n",
      "| time/              |          |\n",
      "|    episodes        | 256      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 541      |\n",
      "|    total_timesteps | 46080    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -26.5    |\n",
      "|    critic_loss     | 3.78     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 45979    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 140      |\n",
      "| time/              |          |\n",
      "|    episodes        | 260      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 549      |\n",
      "|    total_timesteps | 46800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -25.2    |\n",
      "|    critic_loss     | 2.29     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 46699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 142      |\n",
      "| time/              |          |\n",
      "|    episodes        | 264      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 557      |\n",
      "|    total_timesteps | 47520    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -24      |\n",
      "|    critic_loss     | 5.82     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 47419    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 143      |\n",
      "| time/              |          |\n",
      "|    episodes        | 268      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 565      |\n",
      "|    total_timesteps | 48240    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -24.7    |\n",
      "|    critic_loss     | 5.01     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 48139    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 144      |\n",
      "| time/              |          |\n",
      "|    episodes        | 272      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 573      |\n",
      "|    total_timesteps | 48960    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -23      |\n",
      "|    critic_loss     | 3.44     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 48859    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 147      |\n",
      "| time/              |          |\n",
      "|    episodes        | 276      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 581      |\n",
      "|    total_timesteps | 49680    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -24.2    |\n",
      "|    critic_loss     | 2.52     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 49579    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 148      |\n",
      "| time/              |          |\n",
      "|    episodes        | 280      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 590      |\n",
      "|    total_timesteps | 50400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -24.3    |\n",
      "|    critic_loss     | 3.79     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 50299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 150      |\n",
      "| time/              |          |\n",
      "|    episodes        | 284      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 598      |\n",
      "|    total_timesteps | 51120    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -23.3    |\n",
      "|    critic_loss     | 2.21     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 51019    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 151      |\n",
      "| time/              |          |\n",
      "|    episodes        | 288      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 606      |\n",
      "|    total_timesteps | 51840    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -24.3    |\n",
      "|    critic_loss     | 3.6      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 51739    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 152      |\n",
      "| time/              |          |\n",
      "|    episodes        | 292      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 615      |\n",
      "|    total_timesteps | 52560    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -24.6    |\n",
      "|    critic_loss     | 2.65     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 52459    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 153      |\n",
      "| time/              |          |\n",
      "|    episodes        | 296      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 623      |\n",
      "|    total_timesteps | 53280    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -22.6    |\n",
      "|    critic_loss     | 5.58     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 53179    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 154      |\n",
      "| time/              |          |\n",
      "|    episodes        | 300      |\n",
      "|    fps             | 85       |\n",
      "|    time_elapsed    | 631      |\n",
      "|    total_timesteps | 54000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -21.5    |\n",
      "|    critic_loss     | 2.47     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 53899    |\n",
      "---------------------------------\n",
      "âœ… Training curve saved to: td3_rewards_sigma_0.10.png\n",
      "ðŸ“Š Total reward: 40759.38\n",
      "ðŸ“‰ Reward variation (std dev): 31.76\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "\n",
      "=== Training with Ïƒ = 0.20 ===\n",
      "Logging to ./aqua_tensorboard/sigma_0.20\\TD3_3\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 35.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 103      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 720      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.29    |\n",
      "|    critic_loss     | 0.468    |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 619      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 76.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 98       |\n",
      "|    time_elapsed    | 14       |\n",
      "|    total_timesteps | 1440     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.18    |\n",
      "|    critic_loss     | 1.03     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 1339     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 95.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 96       |\n",
      "|    time_elapsed    | 22       |\n",
      "|    total_timesteps | 2160     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.84    |\n",
      "|    critic_loss     | 1.48     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2059     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 104      |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 92       |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 2880     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.79    |\n",
      "|    critic_loss     | 1.34     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 2779     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 110      |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 40       |\n",
      "|    total_timesteps | 3600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -9.07    |\n",
      "|    critic_loss     | 2.12     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 3499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 113      |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 48       |\n",
      "|    total_timesteps | 4320     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -10.2    |\n",
      "|    critic_loss     | 1.41     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 4219     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 115      |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 56       |\n",
      "|    total_timesteps | 5040     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -11.1    |\n",
      "|    critic_loss     | 1.01     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 4939     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 118      |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 65       |\n",
      "|    total_timesteps | 5760     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -12.1    |\n",
      "|    critic_loss     | 3.09     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 5659     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 120      |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 74       |\n",
      "|    total_timesteps | 6480     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -13.3    |\n",
      "|    critic_loss     | 1.35     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 6379     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 122      |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 82       |\n",
      "|    total_timesteps | 7200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.2    |\n",
      "|    critic_loss     | 2.31     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 7099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 124      |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 90       |\n",
      "|    total_timesteps | 7920     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -14.9    |\n",
      "|    critic_loss     | 2.4      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 7819     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 124      |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 98       |\n",
      "|    total_timesteps | 8640     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -15.5    |\n",
      "|    critic_loss     | 2.03     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 8539     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 125      |\n",
      "| time/              |          |\n",
      "|    episodes        | 52       |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 107      |\n",
      "|    total_timesteps | 9360     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -16.6    |\n",
      "|    critic_loss     | 1.58     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 9259     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 125      |\n",
      "| time/              |          |\n",
      "|    episodes        | 56       |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 115      |\n",
      "|    total_timesteps | 10080    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -17.9    |\n",
      "|    critic_loss     | 2.02     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 9979     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 126      |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 123      |\n",
      "|    total_timesteps | 10800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -18      |\n",
      "|    critic_loss     | 1.77     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 10699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 127      |\n",
      "| time/              |          |\n",
      "|    episodes        | 64       |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 131      |\n",
      "|    total_timesteps | 11520    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -18.4    |\n",
      "|    critic_loss     | 1.66     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 11419    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 128      |\n",
      "| time/              |          |\n",
      "|    episodes        | 68       |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 139      |\n",
      "|    total_timesteps | 12240    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -20.1    |\n",
      "|    critic_loss     | 2.02     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 12139    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 128      |\n",
      "| time/              |          |\n",
      "|    episodes        | 72       |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 147      |\n",
      "|    total_timesteps | 12960    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -21.6    |\n",
      "|    critic_loss     | 1.61     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 12859    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 128      |\n",
      "| time/              |          |\n",
      "|    episodes        | 76       |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 155      |\n",
      "|    total_timesteps | 13680    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -20      |\n",
      "|    critic_loss     | 4.59     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 13579    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 129      |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 163      |\n",
      "|    total_timesteps | 14400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -21.1    |\n",
      "|    critic_loss     | 1.72     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 14299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 129      |\n",
      "| time/              |          |\n",
      "|    episodes        | 84       |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 171      |\n",
      "|    total_timesteps | 15120    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -21.6    |\n",
      "|    critic_loss     | 1.14     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 15019    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 129      |\n",
      "| time/              |          |\n",
      "|    episodes        | 88       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 179      |\n",
      "|    total_timesteps | 15840    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -21.1    |\n",
      "|    critic_loss     | 1.88     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 15739    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 130      |\n",
      "| time/              |          |\n",
      "|    episodes        | 92       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 187      |\n",
      "|    total_timesteps | 16560    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -23.6    |\n",
      "|    critic_loss     | 1.35     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 16459    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 130      |\n",
      "| time/              |          |\n",
      "|    episodes        | 96       |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 195      |\n",
      "|    total_timesteps | 17280    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -24.2    |\n",
      "|    critic_loss     | 1.55     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 17179    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 131      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 203      |\n",
      "|    total_timesteps | 18000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -23.1    |\n",
      "|    critic_loss     | 2.55     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 17899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 135      |\n",
      "| time/              |          |\n",
      "|    episodes        | 104      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 211      |\n",
      "|    total_timesteps | 18720    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -23.9    |\n",
      "|    critic_loss     | 2.28     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 18619    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 136      |\n",
      "| time/              |          |\n",
      "|    episodes        | 108      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 219      |\n",
      "|    total_timesteps | 19440    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -26.7    |\n",
      "|    critic_loss     | 1.74     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 19339    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 136      |\n",
      "| time/              |          |\n",
      "|    episodes        | 112      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 227      |\n",
      "|    total_timesteps | 20160    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -24.8    |\n",
      "|    critic_loss     | 2.37     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 20059    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 137      |\n",
      "| time/              |          |\n",
      "|    episodes        | 116      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 235      |\n",
      "|    total_timesteps | 20880    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -25.7    |\n",
      "|    critic_loss     | 2.18     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 20779    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 137      |\n",
      "| time/              |          |\n",
      "|    episodes        | 120      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 243      |\n",
      "|    total_timesteps | 21600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -25.6    |\n",
      "|    critic_loss     | 2.2      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 21499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 138      |\n",
      "| time/              |          |\n",
      "|    episodes        | 124      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 251      |\n",
      "|    total_timesteps | 22320    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -25.3    |\n",
      "|    critic_loss     | 3.14     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 22219    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 139      |\n",
      "| time/              |          |\n",
      "|    episodes        | 128      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 259      |\n",
      "|    total_timesteps | 23040    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -25.3    |\n",
      "|    critic_loss     | 2.87     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 22939    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 139      |\n",
      "| time/              |          |\n",
      "|    episodes        | 132      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 268      |\n",
      "|    total_timesteps | 23760    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -24.4    |\n",
      "|    critic_loss     | 3.44     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 23659    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 140      |\n",
      "| time/              |          |\n",
      "|    episodes        | 136      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 276      |\n",
      "|    total_timesteps | 24480    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -26      |\n",
      "|    critic_loss     | 2.84     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 24379    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 140      |\n",
      "| time/              |          |\n",
      "|    episodes        | 140      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 285      |\n",
      "|    total_timesteps | 25200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -26.3    |\n",
      "|    critic_loss     | 3.15     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 25099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 140      |\n",
      "| time/              |          |\n",
      "|    episodes        | 144      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 293      |\n",
      "|    total_timesteps | 25920    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -25.5    |\n",
      "|    critic_loss     | 4.61     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 25819    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 140      |\n",
      "| time/              |          |\n",
      "|    episodes        | 148      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 301      |\n",
      "|    total_timesteps | 26640    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -28.4    |\n",
      "|    critic_loss     | 2.18     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 26539    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 140      |\n",
      "| time/              |          |\n",
      "|    episodes        | 152      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 309      |\n",
      "|    total_timesteps | 27360    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -28.3    |\n",
      "|    critic_loss     | 2.7      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 27259    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 140      |\n",
      "| time/              |          |\n",
      "|    episodes        | 156      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 317      |\n",
      "|    total_timesteps | 28080    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -28.9    |\n",
      "|    critic_loss     | 3.54     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 27979    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 140      |\n",
      "| time/              |          |\n",
      "|    episodes        | 160      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 325      |\n",
      "|    total_timesteps | 28800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -26.8    |\n",
      "|    critic_loss     | 3.02     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 28699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 140      |\n",
      "| time/              |          |\n",
      "|    episodes        | 164      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 334      |\n",
      "|    total_timesteps | 29520    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -28.2    |\n",
      "|    critic_loss     | 3.2      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 29419    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 140      |\n",
      "| time/              |          |\n",
      "|    episodes        | 168      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 343      |\n",
      "|    total_timesteps | 30240    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -28.1    |\n",
      "|    critic_loss     | 1.6      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 30139    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 141      |\n",
      "| time/              |          |\n",
      "|    episodes        | 172      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 351      |\n",
      "|    total_timesteps | 30960    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -30.4    |\n",
      "|    critic_loss     | 3.4      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 30859    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 141      |\n",
      "| time/              |          |\n",
      "|    episodes        | 176      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 359      |\n",
      "|    total_timesteps | 31680    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -27.8    |\n",
      "|    critic_loss     | 5.76     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 31579    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 141      |\n",
      "| time/              |          |\n",
      "|    episodes        | 180      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 367      |\n",
      "|    total_timesteps | 32400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -29.9    |\n",
      "|    critic_loss     | 4.31     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 32299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 141      |\n",
      "| time/              |          |\n",
      "|    episodes        | 184      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 375      |\n",
      "|    total_timesteps | 33120    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -29.6    |\n",
      "|    critic_loss     | 3.34     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 33019    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 142      |\n",
      "| time/              |          |\n",
      "|    episodes        | 188      |\n",
      "|    fps             | 87       |\n",
      "|    time_elapsed    | 384      |\n",
      "|    total_timesteps | 33840    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -29.1    |\n",
      "|    critic_loss     | 2.68     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 33739    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 142      |\n",
      "| time/              |          |\n",
      "|    episodes        | 192      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 392      |\n",
      "|    total_timesteps | 34560    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -26.8    |\n",
      "|    critic_loss     | 2.08     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 34459    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 142      |\n",
      "| time/              |          |\n",
      "|    episodes        | 196      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 400      |\n",
      "|    total_timesteps | 35280    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -31.2    |\n",
      "|    critic_loss     | 4.03     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 35179    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 143      |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 408      |\n",
      "|    total_timesteps | 36000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -29.8    |\n",
      "|    critic_loss     | 5.07     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 35899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 143      |\n",
      "| time/              |          |\n",
      "|    episodes        | 204      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 416      |\n",
      "|    total_timesteps | 36720    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -29.7    |\n",
      "|    critic_loss     | 1.97     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 36619    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 143      |\n",
      "| time/              |          |\n",
      "|    episodes        | 208      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 424      |\n",
      "|    total_timesteps | 37440    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -28.9    |\n",
      "|    critic_loss     | 5.12     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 37339    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 144      |\n",
      "| time/              |          |\n",
      "|    episodes        | 212      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 432      |\n",
      "|    total_timesteps | 38160    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -29.4    |\n",
      "|    critic_loss     | 5.88     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 38059    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 144      |\n",
      "| time/              |          |\n",
      "|    episodes        | 216      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 440      |\n",
      "|    total_timesteps | 38880    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -31.3    |\n",
      "|    critic_loss     | 6.35     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 38779    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 144      |\n",
      "| time/              |          |\n",
      "|    episodes        | 220      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 448      |\n",
      "|    total_timesteps | 39600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -31      |\n",
      "|    critic_loss     | 4.74     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 39499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 144      |\n",
      "| time/              |          |\n",
      "|    episodes        | 224      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 456      |\n",
      "|    total_timesteps | 40320    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -29.5    |\n",
      "|    critic_loss     | 6.03     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 40219    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 145      |\n",
      "| time/              |          |\n",
      "|    episodes        | 228      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 464      |\n",
      "|    total_timesteps | 41040    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -28.2    |\n",
      "|    critic_loss     | 5.07     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 40939    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 145      |\n",
      "| time/              |          |\n",
      "|    episodes        | 232      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 472      |\n",
      "|    total_timesteps | 41760    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -30.6    |\n",
      "|    critic_loss     | 3.24     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 41659    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 146      |\n",
      "| time/              |          |\n",
      "|    episodes        | 236      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 480      |\n",
      "|    total_timesteps | 42480    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -30.2    |\n",
      "|    critic_loss     | 1.46     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 42379    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 146      |\n",
      "| time/              |          |\n",
      "|    episodes        | 240      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 488      |\n",
      "|    total_timesteps | 43200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -28.4    |\n",
      "|    critic_loss     | 4.32     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 43099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 147      |\n",
      "| time/              |          |\n",
      "|    episodes        | 244      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 496      |\n",
      "|    total_timesteps | 43920    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -25.2    |\n",
      "|    critic_loss     | 6.45     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 43819    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 147      |\n",
      "| time/              |          |\n",
      "|    episodes        | 248      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 503      |\n",
      "|    total_timesteps | 44640    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -30.8    |\n",
      "|    critic_loss     | 3.85     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 44539    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 148      |\n",
      "| time/              |          |\n",
      "|    episodes        | 252      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 511      |\n",
      "|    total_timesteps | 45360    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -28.7    |\n",
      "|    critic_loss     | 4.97     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 45259    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 149      |\n",
      "| time/              |          |\n",
      "|    episodes        | 256      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 520      |\n",
      "|    total_timesteps | 46080    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -31.4    |\n",
      "|    critic_loss     | 4.89     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 45979    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 149      |\n",
      "| time/              |          |\n",
      "|    episodes        | 260      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 528      |\n",
      "|    total_timesteps | 46800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -30.9    |\n",
      "|    critic_loss     | 4.06     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 46699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 150      |\n",
      "| time/              |          |\n",
      "|    episodes        | 264      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 536      |\n",
      "|    total_timesteps | 47520    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -26.4    |\n",
      "|    critic_loss     | 8.5      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 47419    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 151      |\n",
      "| time/              |          |\n",
      "|    episodes        | 268      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 544      |\n",
      "|    total_timesteps | 48240    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -32.3    |\n",
      "|    critic_loss     | 2.29     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 48139    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 151      |\n",
      "| time/              |          |\n",
      "|    episodes        | 272      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 553      |\n",
      "|    total_timesteps | 48960    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -30.3    |\n",
      "|    critic_loss     | 5.47     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 48859    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 152      |\n",
      "| time/              |          |\n",
      "|    episodes        | 276      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 561      |\n",
      "|    total_timesteps | 49680    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -30.4    |\n",
      "|    critic_loss     | 2.64     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 49579    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 152      |\n",
      "| time/              |          |\n",
      "|    episodes        | 280      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 569      |\n",
      "|    total_timesteps | 50400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -31.2    |\n",
      "|    critic_loss     | 4.72     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 50299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 152      |\n",
      "| time/              |          |\n",
      "|    episodes        | 284      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 577      |\n",
      "|    total_timesteps | 51120    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -31.1    |\n",
      "|    critic_loss     | 2.96     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 51019    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 152      |\n",
      "| time/              |          |\n",
      "|    episodes        | 288      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 585      |\n",
      "|    total_timesteps | 51840    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -29.8    |\n",
      "|    critic_loss     | 2.28     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 51739    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 152      |\n",
      "| time/              |          |\n",
      "|    episodes        | 292      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 593      |\n",
      "|    total_timesteps | 52560    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -32.9    |\n",
      "|    critic_loss     | 2.97     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 52459    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 152      |\n",
      "| time/              |          |\n",
      "|    episodes        | 296      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 601      |\n",
      "|    total_timesteps | 53280    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -27.9    |\n",
      "|    critic_loss     | 3.5      |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 53179    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 152      |\n",
      "| time/              |          |\n",
      "|    episodes        | 300      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 609      |\n",
      "|    total_timesteps | 54000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -30.5    |\n",
      "|    critic_loss     | 2.29     |\n",
      "|    learning_rate   | 0.001    |\n",
      "|    n_updates       | 53899    |\n",
      "---------------------------------\n",
      "âœ… Training curve saved to: td3_rewards_sigma_0.20.png\n",
      "ðŸ“Š Total reward: 42556.57\n",
      "ðŸ“‰ Reward variation (std dev): 15.85\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from envs.aquaculture_env import AquacultureEnv\n",
    "from utils.plot_callback import PlotCallback\n",
    "from stable_baselines3 import TD3\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "base_env = AquacultureEnv(region=\"north_sulawesi\")\n",
    "check_env(base_env)\n",
    "\n",
    "noise_sigmas = [0.05, 0.10, 0.20]\n",
    "\n",
    "for sigma in noise_sigmas:\n",
    "    env = AquacultureEnv(region=\"north_sulawesi\")\n",
    "    n_actions = env.action_space.shape[-1]\n",
    "\n",
    "    action_noise = NormalActionNoise(\n",
    "        mean=np.zeros(n_actions),\n",
    "        sigma=np.ones(n_actions) * sigma\n",
    "    )\n",
    "\n",
    "    cb = PlotCallback(\n",
    "        window=1,\n",
    "        save_path=f\"td3_rewards_sigma_{sigma:.2f}.png\",\n",
    "        title=f\"TD3 Training (Ïƒ={sigma:.2f})\"\n",
    "    )\n",
    "\n",
    "    model = TD3(\n",
    "        \"MlpPolicy\",\n",
    "        env,\n",
    "        action_noise=action_noise,\n",
    "        verbose=1,\n",
    "        tensorboard_log=f\"./aqua_tensorboard/sigma_{sigma:.2f}\",\n",
    "        learning_rate=1e-3,\n",
    "        batch_size=256,\n",
    "        gamma=0.99,\n",
    "        device=\"cuda\"\n",
    "    )\n",
    "\n",
    "    print(f\"\\n=== Training with Ïƒ = {sigma:.2f} ===\")\n",
    "    model.learn(total_timesteps=180 * 300, callback=cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-25 02:01:26,286] A new study created in memory with name: no-name-9d607ae2-751a-4ad4-8e3f-3bfe607221fb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=900, episode_reward=22.10 +/- 1.91\n",
      "Episode length: 180.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=1800, episode_reward=104.98 +/- 0.90\n",
      "Episode length: 180.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=2700, episode_reward=123.31 +/- 0.99\n",
      "Episode length: 180.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=3600, episode_reward=133.00 +/- 0.96\n",
      "Episode length: 180.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=4500, episode_reward=143.41 +/- 0.86\n",
      "Episode length: 180.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=5400, episode_reward=159.97 +/- 0.83\n",
      "Episode length: 180.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=6300, episode_reward=157.02 +/- 0.86\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=7200, episode_reward=139.08 +/- 1.30\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=8100, episode_reward=145.64 +/- 0.88\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=9000, episode_reward=156.33 +/- 0.82\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=9900, episode_reward=164.06 +/- 0.88\n",
      "Episode length: 180.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=10800, episode_reward=160.70 +/- 0.97\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=11700, episode_reward=152.38 +/- 1.32\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=12600, episode_reward=110.69 +/- 1.99\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=13500, episode_reward=99.94 +/- 1.17\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=14400, episode_reward=88.91 +/- 1.56\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=15300, episode_reward=95.48 +/- 1.96\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=16200, episode_reward=138.99 +/- 1.36\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=17100, episode_reward=103.97 +/- 1.64\n",
      "Episode length: 180.00 +/- 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-25 02:07:09,304] Trial 0 finished with value: 164.0621950901259 and parameters: {'learning_rate': 0.0006271977619625876, 'gamma': 0.9978334421101541, 'tau': 0.00045369660541676556, 'batch_size': 256, 'net_arch': [256, 256]}. Best is trial 0 with value: 164.0621950901259.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=18000, episode_reward=135.05 +/- 0.95\n",
      "Episode length: 180.00 +/- 0.00\n",
      "âœ… Training curve saved to: plots\\20250425_020126_trial00_rewards.png\n",
      "ðŸ“Š Total reward: 11794.75\n",
      "ðŸ“‰ Reward variation (std dev): 29.75\n",
      "Eval num_timesteps=900, episode_reward=97.15 +/- 1.38\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=1800, episode_reward=149.69 +/- 1.32\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=2700, episode_reward=153.26 +/- 0.99\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=3600, episode_reward=143.45 +/- 1.86\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=4500, episode_reward=134.35 +/- 1.05\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=5400, episode_reward=147.24 +/- 1.25\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=6300, episode_reward=126.37 +/- 1.64\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=7200, episode_reward=119.70 +/- 1.12\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=8100, episode_reward=129.32 +/- 1.31\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=9000, episode_reward=145.24 +/- 1.15\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=9900, episode_reward=147.76 +/- 1.48\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=10800, episode_reward=140.94 +/- 1.41\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=11700, episode_reward=154.11 +/- 1.46\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=12600, episode_reward=141.84 +/- 2.29\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=13500, episode_reward=12.69 +/- 4.12\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=14400, episode_reward=115.53 +/- 2.67\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=15300, episode_reward=162.05 +/- 1.23\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=16200, episode_reward=163.09 +/- 0.88\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=17100, episode_reward=139.14 +/- 1.41\n",
      "Episode length: 180.00 +/- 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-25 02:13:54,678] Trial 1 finished with value: 164.0621950901259 and parameters: {'learning_rate': 0.0008970062217683625, 'gamma': 0.990594816317376, 'tau': 0.0001379818654885925, 'batch_size': 256, 'net_arch': [512, 512, 256]}. Best is trial 0 with value: 164.0621950901259.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=18000, episode_reward=142.69 +/- 1.92\n",
      "Episode length: 180.00 +/- 0.00\n",
      "âœ… Training curve saved to: plots\\20250425_020126_trial01_rewards.png\n",
      "ðŸ“Š Total reward: 11640.05\n",
      "ðŸ“‰ Reward variation (std dev): 19.04\n",
      "Eval num_timesteps=900, episode_reward=29.57 +/- 1.93\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=1800, episode_reward=82.10 +/- 1.35\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=2700, episode_reward=109.84 +/- 1.26\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=3600, episode_reward=119.52 +/- 1.60\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=4500, episode_reward=118.70 +/- 1.56\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=5400, episode_reward=131.54 +/- 1.22\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=6300, episode_reward=128.77 +/- 1.23\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=7200, episode_reward=137.28 +/- 1.02\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=8100, episode_reward=159.76 +/- 1.12\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=9000, episode_reward=163.58 +/- 0.95\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=9900, episode_reward=168.77 +/- 0.65\n",
      "Episode length: 180.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=10800, episode_reward=164.59 +/- 0.90\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=11700, episode_reward=149.86 +/- 1.48\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=12600, episode_reward=161.29 +/- 1.13\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=13500, episode_reward=161.66 +/- 1.00\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=14400, episode_reward=162.54 +/- 0.89\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=15300, episode_reward=147.99 +/- 0.65\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=16200, episode_reward=153.39 +/- 0.91\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=17100, episode_reward=152.59 +/- 1.03\n",
      "Episode length: 180.00 +/- 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-25 02:20:43,964] Trial 2 finished with value: 168.76820621352527 and parameters: {'learning_rate': 0.00034611380503877517, 'gamma': 0.9904807274700478, 'tau': 0.00018948152964641272, 'batch_size': 256, 'net_arch': [512, 512, 256]}. Best is trial 2 with value: 168.76820621352527.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=18000, episode_reward=165.73 +/- 1.18\n",
      "Episode length: 180.00 +/- 0.00\n",
      "âœ… Training curve saved to: plots\\20250425_020126_trial02_rewards.png\n",
      "ðŸ“Š Total reward: 12018.75\n",
      "ðŸ“‰ Reward variation (std dev): 27.09\n",
      "Eval num_timesteps=900, episode_reward=48.08 +/- 1.76\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=1800, episode_reward=57.37 +/- 1.62\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=2700, episode_reward=62.30 +/- 1.69\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=3600, episode_reward=57.09 +/- 1.20\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=4500, episode_reward=58.18 +/- 1.90\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=5400, episode_reward=59.83 +/- 1.54\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=6300, episode_reward=86.62 +/- 1.46\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=7200, episode_reward=121.18 +/- 1.17\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=8100, episode_reward=81.49 +/- 1.45\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=9000, episode_reward=141.38 +/- 1.16\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=9900, episode_reward=150.67 +/- 1.18\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=10800, episode_reward=159.20 +/- 0.99\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=11700, episode_reward=167.17 +/- 0.74\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=12600, episode_reward=173.14 +/- 0.71\n",
      "Episode length: 180.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=13500, episode_reward=170.51 +/- 0.88\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=14400, episode_reward=176.29 +/- 0.90\n",
      "Episode length: 180.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=15300, episode_reward=176.61 +/- 0.71\n",
      "Episode length: 180.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=16200, episode_reward=177.67 +/- 0.65\n",
      "Episode length: 180.00 +/- 0.00\n",
      "New best mean reward!\n",
      "Eval num_timesteps=17100, episode_reward=181.24 +/- 0.50\n",
      "Episode length: 180.00 +/- 0.00\n",
      "New best mean reward!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-25 02:27:06,193] Trial 3 finished with value: 181.24490643223982 and parameters: {'learning_rate': 0.00018913354014134178, 'gamma': 0.9877576938330571, 'tau': 0.00010552262741371088, 'batch_size': 256, 'net_arch': [256, 256]}. Best is trial 3 with value: 181.24490643223982.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=18000, episode_reward=172.14 +/- 0.47\n",
      "Episode length: 180.00 +/- 0.00\n",
      "âœ… Training curve saved to: plots\\20250425_020126_trial03_rewards.png\n",
      "ðŸ“Š Total reward: 10882.02\n",
      "ðŸ“‰ Reward variation (std dev): 36.64\n",
      "Eval num_timesteps=900, episode_reward=49.49 +/- 1.53\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=1800, episode_reward=70.46 +/- 1.28\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=2700, episode_reward=51.10 +/- 2.48\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=3600, episode_reward=124.95 +/- 1.54\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=4500, episode_reward=149.07 +/- 0.66\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=5400, episode_reward=145.51 +/- 1.19\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=6300, episode_reward=148.07 +/- 1.00\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=7200, episode_reward=140.08 +/- 0.78\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=8100, episode_reward=130.70 +/- 1.40\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=9000, episode_reward=137.00 +/- 1.24\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=9900, episode_reward=147.37 +/- 0.74\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=10800, episode_reward=138.63 +/- 0.90\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=11700, episode_reward=125.74 +/- 1.22\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=12600, episode_reward=132.19 +/- 1.15\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=13500, episode_reward=137.94 +/- 1.23\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=14400, episode_reward=132.17 +/- 1.76\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=15300, episode_reward=125.67 +/- 1.22\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=16200, episode_reward=125.16 +/- 1.32\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=17100, episode_reward=112.79 +/- 1.16\n",
      "Episode length: 180.00 +/- 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-25 02:33:53,895] Trial 4 finished with value: 181.24490643223982 and parameters: {'learning_rate': 0.0009773747200034217, 'gamma': 0.9909576095641196, 'tau': 0.00017950031503255874, 'batch_size': 256, 'net_arch': [512, 512, 256]}. Best is trial 3 with value: 181.24490643223982.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=18000, episode_reward=81.99 +/- 2.34\n",
      "Episode length: 180.00 +/- 0.00\n",
      "âœ… Training curve saved to: plots\\20250425_020126_trial04_rewards.png\n",
      "ðŸ“Š Total reward: 10570.96\n",
      "ðŸ“‰ Reward variation (std dev): 24.26\n",
      "Eval num_timesteps=900, episode_reward=72.14 +/- 1.11\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=1800, episode_reward=131.74 +/- 1.21\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=2700, episode_reward=134.27 +/- 0.82\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=3600, episode_reward=143.06 +/- 1.57\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=4500, episode_reward=136.47 +/- 1.63\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=5400, episode_reward=147.14 +/- 0.94\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=6300, episode_reward=152.74 +/- 0.91\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=7200, episode_reward=111.04 +/- 1.08\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=8100, episode_reward=100.90 +/- 1.01\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=9000, episode_reward=92.88 +/- 1.21\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=9900, episode_reward=111.91 +/- 1.27\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=10800, episode_reward=133.24 +/- 0.89\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=11700, episode_reward=135.97 +/- 1.11\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=12600, episode_reward=141.03 +/- 0.85\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=13500, episode_reward=127.13 +/- 1.37\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=14400, episode_reward=131.14 +/- 1.81\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=15300, episode_reward=145.71 +/- 1.21\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=16200, episode_reward=146.17 +/- 0.80\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=17100, episode_reward=150.24 +/- 1.01\n",
      "Episode length: 180.00 +/- 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-25 02:40:42,662] Trial 5 finished with value: 181.24490643223982 and parameters: {'learning_rate': 0.00035098180568504265, 'gamma': 0.9837028049390338, 'tau': 0.0009659869309588304, 'batch_size': 256, 'net_arch': [512, 512, 256]}. Best is trial 3 with value: 181.24490643223982.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=18000, episode_reward=144.97 +/- 1.08\n",
      "Episode length: 180.00 +/- 0.00\n",
      "âœ… Training curve saved to: plots\\20250425_020126_trial05_rewards.png\n",
      "ðŸ“Š Total reward: 11724.91\n",
      "ðŸ“‰ Reward variation (std dev): 16.95\n",
      "Eval num_timesteps=900, episode_reward=27.04 +/- 1.77\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=1800, episode_reward=109.38 +/- 1.58\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=2700, episode_reward=123.62 +/- 1.06\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=3600, episode_reward=126.56 +/- 1.30\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=4500, episode_reward=130.35 +/- 1.70\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=5400, episode_reward=133.64 +/- 1.50\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=6300, episode_reward=118.21 +/- 1.45\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=7200, episode_reward=116.89 +/- 0.98\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=8100, episode_reward=36.12 +/- 4.71\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=9000, episode_reward=2.56 +/- 3.98\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=9900, episode_reward=131.14 +/- 1.12\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=10800, episode_reward=114.40 +/- 1.50\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=11700, episode_reward=151.21 +/- 1.06\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=12600, episode_reward=147.06 +/- 1.17\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=13500, episode_reward=143.13 +/- 0.96\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=14400, episode_reward=134.44 +/- 1.30\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=15300, episode_reward=161.03 +/- 1.36\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=16200, episode_reward=161.60 +/- 0.99\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=17100, episode_reward=153.06 +/- 0.91\n",
      "Episode length: 180.00 +/- 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-25 02:47:35,178] Trial 6 finished with value: 181.24490643223982 and parameters: {'learning_rate': 0.000134628908155563, 'gamma': 0.9836258156404177, 'tau': 0.00010110069420307066, 'batch_size': 128, 'net_arch': [512, 512, 256]}. Best is trial 3 with value: 181.24490643223982.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=18000, episode_reward=157.50 +/- 1.18\n",
      "Episode length: 180.00 +/- 0.00\n",
      "âœ… Training curve saved to: plots\\20250425_020126_trial06_rewards.png\n",
      "ðŸ“Š Total reward: 10339.19\n",
      "ðŸ“‰ Reward variation (std dev): 29.38\n",
      "Eval num_timesteps=900, episode_reward=56.62 +/- 1.07\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=1800, episode_reward=51.30 +/- 1.51\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=2700, episode_reward=133.33 +/- 0.95\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=3600, episode_reward=142.21 +/- 0.92\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=4500, episode_reward=138.06 +/- 1.29\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=5400, episode_reward=136.27 +/- 0.88\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=6300, episode_reward=96.32 +/- 0.94\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=7200, episode_reward=128.62 +/- 1.75\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=8100, episode_reward=92.78 +/- 2.13\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=9000, episode_reward=169.73 +/- 1.69\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=9900, episode_reward=137.45 +/- 1.04\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=10800, episode_reward=166.69 +/- 0.87\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=11700, episode_reward=167.87 +/- 0.93\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=12600, episode_reward=164.87 +/- 0.59\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=13500, episode_reward=170.41 +/- 0.48\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=14400, episode_reward=159.70 +/- 0.43\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=15300, episode_reward=150.19 +/- 0.34\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=16200, episode_reward=158.57 +/- 0.38\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=17100, episode_reward=148.19 +/- 0.56\n",
      "Episode length: 180.00 +/- 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-25 02:53:45,429] Trial 7 finished with value: 181.24490643223982 and parameters: {'learning_rate': 0.00026873682207451826, 'gamma': 0.9926244017930383, 'tau': 0.00024638152862258055, 'batch_size': 256, 'net_arch': [400, 300]}. Best is trial 3 with value: 181.24490643223982.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=18000, episode_reward=141.97 +/- 0.83\n",
      "Episode length: 180.00 +/- 0.00\n",
      "âœ… Training curve saved to: plots\\20250425_020126_trial07_rewards.png\n",
      "ðŸ“Š Total reward: 12312.75\n",
      "ðŸ“‰ Reward variation (std dev): 31.42\n",
      "Eval num_timesteps=900, episode_reward=54.59 +/- 1.75\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=1800, episode_reward=44.53 +/- 1.31\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=2700, episode_reward=108.74 +/- 1.13\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=3600, episode_reward=124.00 +/- 1.07\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=4500, episode_reward=128.02 +/- 1.16\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=5400, episode_reward=132.46 +/- 0.78\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=6300, episode_reward=136.37 +/- 0.78\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=7200, episode_reward=140.64 +/- 1.35\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=8100, episode_reward=146.70 +/- 0.82\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=9000, episode_reward=148.15 +/- 1.47\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=9900, episode_reward=150.04 +/- 0.72\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=10800, episode_reward=148.99 +/- 1.34\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=11700, episode_reward=154.82 +/- 0.77\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=12600, episode_reward=154.94 +/- 1.03\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=13500, episode_reward=145.37 +/- 0.91\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=14400, episode_reward=136.24 +/- 1.15\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=15300, episode_reward=138.85 +/- 0.99\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=16200, episode_reward=131.50 +/- 1.52\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=17100, episode_reward=139.55 +/- 1.18\n",
      "Episode length: 180.00 +/- 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-25 02:59:38,302] Trial 8 finished with value: 181.24490643223982 and parameters: {'learning_rate': 0.00012071371362115884, 'gamma': 0.9895423786874181, 'tau': 0.00011548526523647217, 'batch_size': 256, 'net_arch': [400, 300]}. Best is trial 3 with value: 181.24490643223982.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=18000, episode_reward=138.67 +/- 1.26\n",
      "Episode length: 180.00 +/- 0.00\n",
      "âœ… Training curve saved to: plots\\20250425_020126_trial08_rewards.png\n",
      "ðŸ“Š Total reward: 11099.67\n",
      "ðŸ“‰ Reward variation (std dev): 24.01\n",
      "Eval num_timesteps=900, episode_reward=29.89 +/- 1.83\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=1800, episode_reward=122.91 +/- 1.07\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=2700, episode_reward=152.10 +/- 0.79\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=3600, episode_reward=153.09 +/- 1.06\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=4500, episode_reward=167.17 +/- 0.91\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=5400, episode_reward=144.91 +/- 1.24\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=6300, episode_reward=155.16 +/- 1.54\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=7200, episode_reward=146.29 +/- 1.54\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=8100, episode_reward=146.36 +/- 0.70\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=9000, episode_reward=145.60 +/- 1.10\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=9900, episode_reward=155.18 +/- 0.86\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=10800, episode_reward=165.61 +/- 0.62\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=11700, episode_reward=151.50 +/- 0.91\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=12600, episode_reward=156.01 +/- 0.89\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=13500, episode_reward=149.97 +/- 0.91\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=14400, episode_reward=154.57 +/- 0.80\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=15300, episode_reward=155.37 +/- 0.85\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=16200, episode_reward=156.59 +/- 1.17\n",
      "Episode length: 180.00 +/- 0.00\n",
      "Eval num_timesteps=17100, episode_reward=151.21 +/- 1.26\n",
      "Episode length: 180.00 +/- 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-25 03:05:31,753] Trial 9 finished with value: 181.24490643223982 and parameters: {'learning_rate': 0.0003554717159908246, 'gamma': 0.9822910707292413, 'tau': 0.000742908718306906, 'batch_size': 128, 'net_arch': [400, 300]}. Best is trial 3 with value: 181.24490643223982.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=18000, episode_reward=143.67 +/- 1.18\n",
      "Episode length: 180.00 +/- 0.00\n",
      "âœ… Training curve saved to: plots\\20250425_020126_trial09_rewards.png\n",
      "ðŸ“Š Total reward: 12821.56\n",
      "ðŸ“‰ Reward variation (std dev): 25.55\n",
      "Best value: 181.24490643223982\n",
      "Best params: {'learning_rate': 0.00018913354014134178, 'gamma': 0.9877576938330571, 'tau': 0.00010552262741371088, 'batch_size': 256, 'net_arch': [256, 256]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import optuna\n",
    "import os\n",
    "from datetime import datetime\n",
    "from stable_baselines3 import TD3\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "from envs.aquaculture_env import AquacultureEnv\n",
    "from utils.plot_callback import PlotCallback\n",
    "\n",
    "PLOT_DIR = \"plots\"\n",
    "os.makedirs(PLOT_DIR, exist_ok=True)\n",
    "RUN_ID   = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "FIXED_NOISE_SCALE = 0.20\n",
    "\n",
    "eval_env = AquacultureEnv(region=\"north_sulawesi\")\n",
    "eval_cb  = EvalCallback(\n",
    "    eval_env,\n",
    "    n_eval_episodes=20,\n",
    "    eval_freq=180 * 5,\n",
    "    deterministic=True\n",
    ")\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    lr    = trial.suggest_float(\"learning_rate\", 1e-4,   1e-3,  log=True)\n",
    "    gamma = trial.suggest_float(\"gamma\",          0.98,   0.999)\n",
    "    tau   = trial.suggest_float(\"tau\",            1e-4,   1e-3,  log=True)\n",
    "    batch = trial.suggest_categorical(\"batch_size\", [128, 256])\n",
    "    net   = trial.suggest_categorical(\n",
    "                \"net_arch\",\n",
    "                [[256, 256], [400, 300], [512, 512, 256]]\n",
    "            )\n",
    "    \n",
    "    env = AquacultureEnv(region=\"north_sulawesi\")\n",
    "    n_actions = env.action_space.shape[-1]\n",
    "    action_noise = NormalActionNoise(\n",
    "        mean=np.zeros(n_actions),\n",
    "        sigma=np.ones(n_actions) * FIXED_NOISE_SCALE\n",
    "    )\n",
    "    \n",
    "    model = TD3(\n",
    "        \"MlpPolicy\",\n",
    "        env,\n",
    "        learning_rate=lr,\n",
    "        gamma=gamma,\n",
    "        tau=tau,\n",
    "        batch_size=batch,\n",
    "        target_policy_noise=FIXED_NOISE_SCALE,\n",
    "        target_noise_clip=FIXED_NOISE_SCALE,\n",
    "        policy_kwargs=dict(net_arch=net),\n",
    "        action_noise=action_noise,\n",
    "        verbose=0,\n",
    "        tensorboard_log=\"./aqua_tensorboard\",\n",
    "        device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    )\n",
    "\n",
    "    fname = f\"{RUN_ID}_trial{trial.number:02d}_rewards.png\"\n",
    "    save_path = os.path.join(PLOT_DIR, fname)\n",
    "\n",
    "    plot_cb = PlotCallback(\n",
    "        window=1,\n",
    "        save_path=save_path,\n",
    "        title=f\"Trial {trial.number} Rewards\"\n",
    "    )\n",
    "\n",
    "    model.learn(180 * 100, callback=[eval_cb, plot_cb])\n",
    "    return eval_cb.best_mean_reward\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    sampler=optuna.samplers.TPESampler()\n",
    ")\n",
    "study.optimize(objective, n_trials=10, timeout=3 * 3600)\n",
    "\n",
    "print(\"Best value:\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./aqua_tensorboard\\TD3_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yigal Lim\\AppData\\Roaming\\Python\\Python312\\site-packages\\stable_baselines3\\common\\env_checker.py:462: UserWarning: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) cf. https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 33.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 103      |\n",
      "|    time_elapsed    | 6        |\n",
      "|    total_timesteps | 720      |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.492   |\n",
      "|    critic_loss     | 0.227    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 619      |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 36.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 93       |\n",
      "|    time_elapsed    | 15       |\n",
      "|    total_timesteps | 1440     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.541   |\n",
      "|    critic_loss     | 0.213    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 1339     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 43.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 91       |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 2160     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.443   |\n",
      "|    critic_loss     | 0.241    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 2059     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 46.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 91       |\n",
      "|    time_elapsed    | 31       |\n",
      "|    total_timesteps | 2880     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.481   |\n",
      "|    critic_loss     | 0.266    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 2779     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 49.7     |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 90       |\n",
      "|    time_elapsed    | 39       |\n",
      "|    total_timesteps | 3600     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.687   |\n",
      "|    critic_loss     | 0.354    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 3499     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 56.5     |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 91       |\n",
      "|    time_elapsed    | 47       |\n",
      "|    total_timesteps | 4320     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.5     |\n",
      "|    critic_loss     | 0.4      |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 4219     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 63.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 90       |\n",
      "|    time_elapsed    | 55       |\n",
      "|    total_timesteps | 5040     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.795   |\n",
      "|    critic_loss     | 0.376    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 4939     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 68.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 64       |\n",
      "|    total_timesteps | 5760     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.855   |\n",
      "|    critic_loss     | 0.322    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 5659     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 73.6     |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 72       |\n",
      "|    total_timesteps | 6480     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.893   |\n",
      "|    critic_loss     | 0.405    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 6379     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 77.7     |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 80       |\n",
      "|    total_timesteps | 7200     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.924   |\n",
      "|    critic_loss     | 0.637    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 7099     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 80.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 88       |\n",
      "|    total_timesteps | 7920     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -0.881   |\n",
      "|    critic_loss     | 0.367    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 7819     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 84.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 96       |\n",
      "|    total_timesteps | 8640     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.11    |\n",
      "|    critic_loss     | 0.442    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 8539     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 86.7     |\n",
      "| time/              |          |\n",
      "|    episodes        | 52       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 104      |\n",
      "|    total_timesteps | 9360     |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.1     |\n",
      "|    critic_loss     | 0.437    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 9259     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 89.2     |\n",
      "| time/              |          |\n",
      "|    episodes        | 56       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 10080    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.22    |\n",
      "|    critic_loss     | 0.461    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 9979     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 91.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 120      |\n",
      "|    total_timesteps | 10800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.24    |\n",
      "|    critic_loss     | 0.576    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 10699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 93       |\n",
      "| time/              |          |\n",
      "|    episodes        | 64       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 128      |\n",
      "|    total_timesteps | 11520    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.59    |\n",
      "|    critic_loss     | 0.672    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 11419    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 94.7     |\n",
      "| time/              |          |\n",
      "|    episodes        | 68       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 136      |\n",
      "|    total_timesteps | 12240    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.41    |\n",
      "|    critic_loss     | 0.534    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 12139    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 96.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 72       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 144      |\n",
      "|    total_timesteps | 12960    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.55    |\n",
      "|    critic_loss     | 0.413    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 12859    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 97.8     |\n",
      "| time/              |          |\n",
      "|    episodes        | 76       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 153      |\n",
      "|    total_timesteps | 13680    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.81    |\n",
      "|    critic_loss     | 0.407    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 13579    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 99.4     |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 161      |\n",
      "|    total_timesteps | 14400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.76    |\n",
      "|    critic_loss     | 0.498    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 14299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 101      |\n",
      "| time/              |          |\n",
      "|    episodes        | 84       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 169      |\n",
      "|    total_timesteps | 15120    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -1.85    |\n",
      "|    critic_loss     | 0.356    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 15019    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 102      |\n",
      "| time/              |          |\n",
      "|    episodes        | 88       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 177      |\n",
      "|    total_timesteps | 15840    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.15    |\n",
      "|    critic_loss     | 0.407    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 15739    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 103      |\n",
      "| time/              |          |\n",
      "|    episodes        | 92       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 185      |\n",
      "|    total_timesteps | 16560    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.41    |\n",
      "|    critic_loss     | 0.471    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 16459    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 105      |\n",
      "| time/              |          |\n",
      "|    episodes        | 96       |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 193      |\n",
      "|    total_timesteps | 17280    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.68    |\n",
      "|    critic_loss     | 0.571    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 17179    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 106      |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 201      |\n",
      "|    total_timesteps | 18000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.71    |\n",
      "|    critic_loss     | 0.508    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 17899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 110      |\n",
      "| time/              |          |\n",
      "|    episodes        | 104      |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 208      |\n",
      "|    total_timesteps | 18720    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -2.99    |\n",
      "|    critic_loss     | 0.564    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 18619    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 115      |\n",
      "| time/              |          |\n",
      "|    episodes        | 108      |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 216      |\n",
      "|    total_timesteps | 19440    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.23    |\n",
      "|    critic_loss     | 0.62     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 19339    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 118      |\n",
      "| time/              |          |\n",
      "|    episodes        | 112      |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 224      |\n",
      "|    total_timesteps | 20160    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.54    |\n",
      "|    critic_loss     | 0.565    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 20059    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 121      |\n",
      "| time/              |          |\n",
      "|    episodes        | 116      |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 232      |\n",
      "|    total_timesteps | 20880    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.61    |\n",
      "|    critic_loss     | 0.728    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 20779    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 124      |\n",
      "| time/              |          |\n",
      "|    episodes        | 120      |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 240      |\n",
      "|    total_timesteps | 21600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -3.83    |\n",
      "|    critic_loss     | 0.692    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 21499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 127      |\n",
      "| time/              |          |\n",
      "|    episodes        | 124      |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 248      |\n",
      "|    total_timesteps | 22320    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.18    |\n",
      "|    critic_loss     | 0.74     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 22219    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 128      |\n",
      "| time/              |          |\n",
      "|    episodes        | 128      |\n",
      "|    fps             | 90       |\n",
      "|    time_elapsed    | 255      |\n",
      "|    total_timesteps | 23040    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.42    |\n",
      "|    critic_loss     | 0.964    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 22939    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 130      |\n",
      "| time/              |          |\n",
      "|    episodes        | 132      |\n",
      "|    fps             | 90       |\n",
      "|    time_elapsed    | 263      |\n",
      "|    total_timesteps | 23760    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.6     |\n",
      "|    critic_loss     | 0.869    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 23659    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 131      |\n",
      "| time/              |          |\n",
      "|    episodes        | 136      |\n",
      "|    fps             | 90       |\n",
      "|    time_elapsed    | 271      |\n",
      "|    total_timesteps | 24480    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.56    |\n",
      "|    critic_loss     | 0.964    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 24379    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 132      |\n",
      "| time/              |          |\n",
      "|    episodes        | 140      |\n",
      "|    fps             | 90       |\n",
      "|    time_elapsed    | 279      |\n",
      "|    total_timesteps | 25200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.95    |\n",
      "|    critic_loss     | 1.11     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 25099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 133      |\n",
      "| time/              |          |\n",
      "|    episodes        | 144      |\n",
      "|    fps             | 90       |\n",
      "|    time_elapsed    | 286      |\n",
      "|    total_timesteps | 25920    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -4.87    |\n",
      "|    critic_loss     | 0.861    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 25819    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 134      |\n",
      "| time/              |          |\n",
      "|    episodes        | 148      |\n",
      "|    fps             | 90       |\n",
      "|    time_elapsed    | 293      |\n",
      "|    total_timesteps | 26640    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.39    |\n",
      "|    critic_loss     | 0.903    |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 26539    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 135      |\n",
      "| time/              |          |\n",
      "|    episodes        | 152      |\n",
      "|    fps             | 90       |\n",
      "|    time_elapsed    | 301      |\n",
      "|    total_timesteps | 27360    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.15    |\n",
      "|    critic_loss     | 1.33     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 27259    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 136      |\n",
      "| time/              |          |\n",
      "|    episodes        | 156      |\n",
      "|    fps             | 90       |\n",
      "|    time_elapsed    | 309      |\n",
      "|    total_timesteps | 28080    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.57    |\n",
      "|    critic_loss     | 1        |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 27979    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 137      |\n",
      "| time/              |          |\n",
      "|    episodes        | 160      |\n",
      "|    fps             | 90       |\n",
      "|    time_elapsed    | 316      |\n",
      "|    total_timesteps | 28800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.59    |\n",
      "|    critic_loss     | 1.72     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 28699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 138      |\n",
      "| time/              |          |\n",
      "|    episodes        | 164      |\n",
      "|    fps             | 90       |\n",
      "|    time_elapsed    | 324      |\n",
      "|    total_timesteps | 29520    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.83    |\n",
      "|    critic_loss     | 1.31     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 29419    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 139      |\n",
      "| time/              |          |\n",
      "|    episodes        | 168      |\n",
      "|    fps             | 90       |\n",
      "|    time_elapsed    | 332      |\n",
      "|    total_timesteps | 30240    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -5.69    |\n",
      "|    critic_loss     | 1.21     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 30139    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 139      |\n",
      "| time/              |          |\n",
      "|    episodes        | 172      |\n",
      "|    fps             | 90       |\n",
      "|    time_elapsed    | 340      |\n",
      "|    total_timesteps | 30960    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.42    |\n",
      "|    critic_loss     | 1.35     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 30859    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 140      |\n",
      "| time/              |          |\n",
      "|    episodes        | 176      |\n",
      "|    fps             | 90       |\n",
      "|    time_elapsed    | 348      |\n",
      "|    total_timesteps | 31680    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.38    |\n",
      "|    critic_loss     | 1.14     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 31579    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 140      |\n",
      "| time/              |          |\n",
      "|    episodes        | 180      |\n",
      "|    fps             | 90       |\n",
      "|    time_elapsed    | 356      |\n",
      "|    total_timesteps | 32400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.43    |\n",
      "|    critic_loss     | 1.25     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 32299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 141      |\n",
      "| time/              |          |\n",
      "|    episodes        | 184      |\n",
      "|    fps             | 90       |\n",
      "|    time_elapsed    | 364      |\n",
      "|    total_timesteps | 33120    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.1     |\n",
      "|    critic_loss     | 1.61     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 33019    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 142      |\n",
      "| time/              |          |\n",
      "|    episodes        | 188      |\n",
      "|    fps             | 90       |\n",
      "|    time_elapsed    | 373      |\n",
      "|    total_timesteps | 33840    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.54    |\n",
      "|    critic_loss     | 1.38     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 33739    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 141      |\n",
      "| time/              |          |\n",
      "|    episodes        | 192      |\n",
      "|    fps             | 90       |\n",
      "|    time_elapsed    | 381      |\n",
      "|    total_timesteps | 34560    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -6.78    |\n",
      "|    critic_loss     | 1.63     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 34459    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 141      |\n",
      "| time/              |          |\n",
      "|    episodes        | 196      |\n",
      "|    fps             | 90       |\n",
      "|    time_elapsed    | 389      |\n",
      "|    total_timesteps | 35280    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.27    |\n",
      "|    critic_loss     | 1.51     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 35179    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 141      |\n",
      "| time/              |          |\n",
      "|    episodes        | 200      |\n",
      "|    fps             | 90       |\n",
      "|    time_elapsed    | 398      |\n",
      "|    total_timesteps | 36000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.22    |\n",
      "|    critic_loss     | 1.28     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 35899    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 141      |\n",
      "| time/              |          |\n",
      "|    episodes        | 204      |\n",
      "|    fps             | 90       |\n",
      "|    time_elapsed    | 406      |\n",
      "|    total_timesteps | 36720    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.58    |\n",
      "|    critic_loss     | 1.25     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 36619    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 140      |\n",
      "| time/              |          |\n",
      "|    episodes        | 208      |\n",
      "|    fps             | 90       |\n",
      "|    time_elapsed    | 414      |\n",
      "|    total_timesteps | 37440    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.35    |\n",
      "|    critic_loss     | 2.12     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 37339    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 140      |\n",
      "| time/              |          |\n",
      "|    episodes        | 212      |\n",
      "|    fps             | 90       |\n",
      "|    time_elapsed    | 423      |\n",
      "|    total_timesteps | 38160    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.68    |\n",
      "|    critic_loss     | 1.52     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 38059    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 140      |\n",
      "| time/              |          |\n",
      "|    episodes        | 216      |\n",
      "|    fps             | 90       |\n",
      "|    time_elapsed    | 431      |\n",
      "|    total_timesteps | 38880    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.87    |\n",
      "|    critic_loss     | 1.64     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 38779    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 139      |\n",
      "| time/              |          |\n",
      "|    episodes        | 220      |\n",
      "|    fps             | 90       |\n",
      "|    time_elapsed    | 439      |\n",
      "|    total_timesteps | 39600    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.85    |\n",
      "|    critic_loss     | 1.31     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 39499    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 139      |\n",
      "| time/              |          |\n",
      "|    episodes        | 224      |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 448      |\n",
      "|    total_timesteps | 40320    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.04    |\n",
      "|    critic_loss     | 1.66     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 40219    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 138      |\n",
      "| time/              |          |\n",
      "|    episodes        | 228      |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 457      |\n",
      "|    total_timesteps | 41040    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.21    |\n",
      "|    critic_loss     | 1.49     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 40939    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 138      |\n",
      "| time/              |          |\n",
      "|    episodes        | 232      |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 466      |\n",
      "|    total_timesteps | 41760    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.86    |\n",
      "|    critic_loss     | 1.37     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 41659    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 137      |\n",
      "| time/              |          |\n",
      "|    episodes        | 236      |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 474      |\n",
      "|    total_timesteps | 42480    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.78    |\n",
      "|    critic_loss     | 1.43     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 42379    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 137      |\n",
      "| time/              |          |\n",
      "|    episodes        | 240      |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 483      |\n",
      "|    total_timesteps | 43200    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.08    |\n",
      "|    critic_loss     | 1.32     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 43099    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 136      |\n",
      "| time/              |          |\n",
      "|    episodes        | 244      |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 491      |\n",
      "|    total_timesteps | 43920    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.19    |\n",
      "|    critic_loss     | 1.96     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 43819    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 135      |\n",
      "| time/              |          |\n",
      "|    episodes        | 248      |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 500      |\n",
      "|    total_timesteps | 44640    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.07    |\n",
      "|    critic_loss     | 1.16     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 44539    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 135      |\n",
      "| time/              |          |\n",
      "|    episodes        | 252      |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 509      |\n",
      "|    total_timesteps | 45360    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.12    |\n",
      "|    critic_loss     | 1.45     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 45259    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 134      |\n",
      "| time/              |          |\n",
      "|    episodes        | 256      |\n",
      "|    fps             | 89       |\n",
      "|    time_elapsed    | 517      |\n",
      "|    total_timesteps | 46080    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.17    |\n",
      "|    critic_loss     | 2.21     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 45979    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 134      |\n",
      "| time/              |          |\n",
      "|    episodes        | 260      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 525      |\n",
      "|    total_timesteps | 46800    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.31    |\n",
      "|    critic_loss     | 1.51     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 46699    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 134      |\n",
      "| time/              |          |\n",
      "|    episodes        | 264      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 534      |\n",
      "|    total_timesteps | 47520    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.94    |\n",
      "|    critic_loss     | 1.44     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 47419    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 133      |\n",
      "| time/              |          |\n",
      "|    episodes        | 268      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 543      |\n",
      "|    total_timesteps | 48240    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8       |\n",
      "|    critic_loss     | 1.58     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 48139    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 132      |\n",
      "| time/              |          |\n",
      "|    episodes        | 272      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 551      |\n",
      "|    total_timesteps | 48960    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.26    |\n",
      "|    critic_loss     | 1.11     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 48859    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 131      |\n",
      "| time/              |          |\n",
      "|    episodes        | 276      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 559      |\n",
      "|    total_timesteps | 49680    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.54    |\n",
      "|    critic_loss     | 1.31     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 49579    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 131      |\n",
      "| time/              |          |\n",
      "|    episodes        | 280      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 567      |\n",
      "|    total_timesteps | 50400    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.94    |\n",
      "|    critic_loss     | 1.39     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 50299    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 130      |\n",
      "| time/              |          |\n",
      "|    episodes        | 284      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 576      |\n",
      "|    total_timesteps | 51120    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.24    |\n",
      "|    critic_loss     | 1.63     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 51019    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 129      |\n",
      "| time/              |          |\n",
      "|    episodes        | 288      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 584      |\n",
      "|    total_timesteps | 51840    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -7.99    |\n",
      "|    critic_loss     | 1.28     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 51739    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 128      |\n",
      "| time/              |          |\n",
      "|    episodes        | 292      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 592      |\n",
      "|    total_timesteps | 52560    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.3     |\n",
      "|    critic_loss     | 1.42     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 52459    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 128      |\n",
      "| time/              |          |\n",
      "|    episodes        | 296      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 600      |\n",
      "|    total_timesteps | 53280    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.54    |\n",
      "|    critic_loss     | 1.6      |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 53179    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 180      |\n",
      "|    ep_rew_mean     | 127      |\n",
      "| time/              |          |\n",
      "|    episodes        | 300      |\n",
      "|    fps             | 88       |\n",
      "|    time_elapsed    | 608      |\n",
      "|    total_timesteps | 54000    |\n",
      "| train/             |          |\n",
      "|    actor_loss      | -8.25    |\n",
      "|    critic_loss     | 1.19     |\n",
      "|    learning_rate   | 0.0002   |\n",
      "|    n_updates       | 53899    |\n",
      "---------------------------------\n",
      "âœ… Training curve saved to: plots/td3_training_rewards.png\n",
      "ðŸ“Š Total reward: 37414.17\n",
      "ðŸ“‰ Reward variation (std dev): 23.35\n",
      "ðŸ’¾ Model saved to ./saved_model/td3_best_model\n"
     ]
    }
   ],
   "source": [
    "from envs.aquaculture_env import AquacultureEnv\n",
    "from utils.plot_callback import PlotCallback\n",
    "from stable_baselines3 import TD3\n",
    "from stable_baselines3.common.noise import NormalActionNoise\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "\n",
    "env = AquacultureEnv(region=\"north_sulawesi\")\n",
    "check_env(env)\n",
    "\n",
    "FIXED_NOISE_SCALE = 0.20\n",
    "n_actions = env.action_space.shape[0]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=FIXED_NOISE_SCALE * np.ones(n_actions))\n",
    "\n",
    "best_params = {\n",
    "    \"learning_rate\": 0.0002,\n",
    "    \"gamma\": 0.9878,\n",
    "    \"tau\": 0.0001,\n",
    "    \"batch_size\": 256,\n",
    "    \"net_arch\": [256, 256]\n",
    "}\n",
    "\n",
    "model = TD3(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    action_noise=action_noise,\n",
    "    verbose=1,\n",
    "    tensorboard_log=\"./aqua_tensorboard\",\n",
    "    learning_rate=best_params[\"learning_rate\"],\n",
    "    gamma=best_params[\"gamma\"],\n",
    "    tau=best_params[\"tau\"],\n",
    "    batch_size=best_params[\"batch_size\"],\n",
    "    policy_kwargs=dict(net_arch=best_params[\"net_arch\"]),\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "plot_cb = PlotCallback(window=1, save_path=\"plots/td3_training_rewards.png\", title=\"TD3 Training Rewards (Ïƒ=0.20)\")\n",
    "model.learn(total_timesteps=180 * 300, callback=plot_cb)\n",
    "\n",
    "model_save_path = \"./saved_model/td3_best_model\"\n",
    "os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "model.save(model_save_path)\n",
    "print(f\"ðŸ’¾ Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space: Box([ 0.  24.   0.3], [ 1. 40.  1.], (3,), float32)\n",
      "\n",
      "--- Day 1 ---\n",
      "Raw-obs: biomass=1421.5 g, count=100, temp=24.93Â°C, DO=0.60 mg/L, UIA=0.060 mg/L\n",
      "Action: feed_rate=0.617 â†’ feed_amt=87.76 g, temp_set=39.998, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.61\n",
      "Feed Cost:           0.11\n",
      "Heat Cost:           0.10\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.39\n",
      "\n",
      "\n",
      "--- Day 2 ---\n",
      "Raw-obs: biomass=1520.1 g, count=100, temp=28.52Â°C, DO=1.00 mg/L, UIA=0.060 mg/L\n",
      "Action: feed_rate=0.553 â†’ feed_amt=84.08 g, temp_set=39.964, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.81\n",
      "Feed Cost:           0.11\n",
      "Heat Cost:           0.10\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.59\n",
      "\n",
      "\n",
      "--- Day 3 ---\n",
      "Raw-obs: biomass=1651.2 g, count=100, temp=31.03Â°C, DO=1.00 mg/L, UIA=0.060 mg/L\n",
      "Action: feed_rate=0.739 â†’ feed_amt=121.98 g, temp_set=34.767, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.90\n",
      "Feed Cost:           0.15\n",
      "Heat Cost:           0.07\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.66\n",
      "\n",
      "\n",
      "--- Day 4 ---\n",
      "Raw-obs: biomass=1796.3 g, count=100, temp=31.64Â°C, DO=1.00 mg/L, UIA=0.060 mg/L\n",
      "Action: feed_rate=0.748 â†’ feed_amt=134.34 g, temp_set=28.937, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.95\n",
      "Feed Cost:           0.17\n",
      "Heat Cost:           0.03\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.73\n",
      "\n",
      "\n",
      "--- Day 5 ---\n",
      "Raw-obs: biomass=1948.8 g, count=100, temp=31.21Â°C, DO=1.00 mg/L, UIA=0.064 mg/L\n",
      "Action: feed_rate=0.738 â†’ feed_amt=143.86 g, temp_set=32.764, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.00\n",
      "Feed Cost:           0.18\n",
      "Heat Cost:           0.06\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.74\n",
      "\n",
      "\n",
      "--- Day 6 ---\n",
      "Raw-obs: biomass=2110.1 g, count=100, temp=31.19Â°C, DO=1.00 mg/L, UIA=0.069 mg/L\n",
      "Action: feed_rate=0.731 â†’ feed_amt=154.29 g, temp_set=32.416, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.05\n",
      "Feed Cost:           0.19\n",
      "Heat Cost:           0.06\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.79\n",
      "\n",
      "\n",
      "--- Day 7 ---\n",
      "Raw-obs: biomass=2279.7 g, count=100, temp=31.13Â°C, DO=1.00 mg/L, UIA=0.073 mg/L\n",
      "Action: feed_rate=0.726 â†’ feed_amt=165.59 g, temp_set=32.658, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.11\n",
      "Feed Cost:           0.21\n",
      "Heat Cost:           0.06\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.82\n",
      "\n",
      "\n",
      "--- Day 8 ---\n",
      "Raw-obs: biomass=2458.4 g, count=100, temp=31.22Â°C, DO=1.00 mg/L, UIA=0.079 mg/L\n",
      "Action: feed_rate=0.718 â†’ feed_amt=176.57 g, temp_set=31.138, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.15\n",
      "Feed Cost:           0.22\n",
      "Heat Cost:           0.05\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.87\n",
      "\n",
      "\n",
      "--- Day 9 ---\n",
      "Raw-obs: biomass=2644.3 g, count=100, temp=30.81Â°C, DO=1.00 mg/L, UIA=0.082 mg/L\n",
      "Action: feed_rate=0.722 â†’ feed_amt=190.81 g, temp_set=35.131, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.22\n",
      "Feed Cost:           0.24\n",
      "Heat Cost:           0.06\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.91\n",
      "\n",
      "\n",
      "--- Day 10 ---\n",
      "Raw-obs: biomass=2841.6 g, count=100, temp=31.57Â°C, DO=1.00 mg/L, UIA=0.091 mg/L\n",
      "Action: feed_rate=0.702 â†’ feed_amt=199.41 g, temp_set=27.053, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.27\n",
      "Feed Cost:           0.25\n",
      "Heat Cost:           0.03\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.98\n",
      "\n",
      "\n",
      "--- Day 11 ---\n",
      "Raw-obs: biomass=3046.7 g, count=100, temp=31.17Â°C, DO=1.00 mg/L, UIA=0.094 mg/L\n",
      "Action: feed_rate=0.703 â†’ feed_amt=214.09 g, temp_set=30.307, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.32\n",
      "Feed Cost:           0.27\n",
      "Heat Cost:           0.03\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.00\n",
      "\n",
      "\n",
      "--- Day 12 ---\n",
      "Raw-obs: biomass=3259.1 g, count=100, temp=30.76Â°C, DO=1.00 mg/L, UIA=0.097 mg/L\n",
      "Action: feed_rate=0.702 â†’ feed_amt=228.79 g, temp_set=34.337, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.39\n",
      "Feed Cost:           0.28\n",
      "Heat Cost:           0.06\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.04\n",
      "\n",
      "\n",
      "--- Day 13 ---\n",
      "Raw-obs: biomass=3483.4 g, count=100, temp=31.30Â°C, DO=1.00 mg/L, UIA=0.106 mg/L\n",
      "Action: feed_rate=0.684 â†’ feed_amt=238.31 g, temp_set=27.950, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.43\n",
      "Feed Cost:           0.30\n",
      "Heat Cost:           0.03\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.09\n",
      "\n",
      "\n",
      "--- Day 14 ---\n",
      "Raw-obs: biomass=3714.4 g, count=100, temp=30.86Â°C, DO=1.00 mg/L, UIA=0.108 mg/L\n",
      "Action: feed_rate=0.686 â†’ feed_amt=254.88 g, temp_set=32.201, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.49\n",
      "Feed Cost:           0.32\n",
      "Heat Cost:           0.06\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.10\n",
      "\n",
      "\n",
      "--- Day 15 ---\n",
      "Raw-obs: biomass=3954.5 g, count=100, temp=30.77Â°C, DO=1.00 mg/L, UIA=0.114 mg/L\n",
      "Action: feed_rate=0.678 â†’ feed_amt=267.95 g, temp_set=32.661, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.55\n",
      "Feed Cost:           0.33\n",
      "Heat Cost:           0.06\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.14\n",
      "\n",
      "\n",
      "--- Day 16 ---\n",
      "Raw-obs: biomass=4204.2 g, count=100, temp=30.80Â°C, DO=1.00 mg/L, UIA=0.119 mg/L\n",
      "Action: feed_rate=0.675 â†’ feed_amt=283.73 g, temp_set=31.796, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.60\n",
      "Feed Cost:           0.35\n",
      "Heat Cost:           0.06\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.18\n",
      "\n",
      "\n",
      "--- Day 17 ---\n",
      "Raw-obs: biomass=4461.8 g, count=100, temp=30.64Â°C, DO=1.00 mg/L, UIA=0.125 mg/L\n",
      "Action: feed_rate=0.672 â†’ feed_amt=299.90 g, temp_set=33.054, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.67\n",
      "Feed Cost:           0.37\n",
      "Heat Cost:           0.06\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.23\n",
      "\n",
      "\n",
      "--- Day 18 ---\n",
      "Raw-obs: biomass=4730.4 g, count=100, temp=30.83Â°C, DO=1.00 mg/L, UIA=0.132 mg/L\n",
      "Action: feed_rate=0.669 â†’ feed_amt=316.49 g, temp_set=30.373, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.70\n",
      "Feed Cost:           0.39\n",
      "Heat Cost:           0.04\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.25\n",
      "\n",
      "\n",
      "--- Day 19 ---\n",
      "Raw-obs: biomass=5004.2 g, count=100, temp=30.46Â°C, DO=1.00 mg/L, UIA=0.136 mg/L\n",
      "Action: feed_rate=0.666 â†’ feed_amt=333.16 g, temp_set=34.009, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.79\n",
      "Feed Cost:           0.41\n",
      "Heat Cost:           0.05\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.31\n",
      "\n",
      "\n",
      "--- Day 20 ---\n",
      "Raw-obs: biomass=5292.3 g, count=100, temp=30.94Â°C, DO=1.00 mg/L, UIA=0.146 mg/L\n",
      "Action: feed_rate=0.663 â†’ feed_amt=350.76 g, temp_set=28.246, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.82\n",
      "Feed Cost:           0.43\n",
      "Heat Cost:           0.03\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.35\n",
      "\n",
      "\n",
      "--- Day 21 ---\n",
      "Raw-obs: biomass=5586.0 g, count=100, temp=30.61Â°C, DO=1.00 mg/L, UIA=0.151 mg/L\n",
      "Action: feed_rate=0.660 â†’ feed_amt=368.51 g, temp_set=31.117, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.86\n",
      "Feed Cost:           0.45\n",
      "Heat Cost:           0.04\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.36\n",
      "\n",
      "\n",
      "--- Day 22 ---\n",
      "Raw-obs: biomass=5886.4 g, count=100, temp=30.41Â°C, DO=1.00 mg/L, UIA=0.155 mg/L\n",
      "Action: feed_rate=0.656 â†’ feed_amt=385.88 g, temp_set=32.861, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.94\n",
      "Feed Cost:           0.47\n",
      "Heat Cost:           0.05\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.41\n",
      "\n",
      "\n",
      "--- Day 23 ---\n",
      "Raw-obs: biomass=6199.8 g, count=100, temp=30.68Â°C, DO=1.00 mg/L, UIA=0.164 mg/L\n",
      "Action: feed_rate=0.653 â†’ feed_amt=404.79 g, temp_set=29.317, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.96\n",
      "Feed Cost:           0.49\n",
      "Heat Cost:           0.03\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.42\n",
      "\n",
      "\n",
      "--- Day 24 ---\n",
      "Raw-obs: biomass=6515.8 g, count=100, temp=30.28Â°C, DO=1.00 mg/L, UIA=0.168 mg/L\n",
      "Action: feed_rate=0.647 â†’ feed_amt=421.62 g, temp_set=33.064, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.06\n",
      "Feed Cost:           0.51\n",
      "Heat Cost:           0.06\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.46\n",
      "\n",
      "\n",
      "--- Day 25 ---\n",
      "Raw-obs: biomass=6847.5 g, count=100, temp=30.69Â°C, DO=1.00 mg/L, UIA=0.177 mg/L\n",
      "Action: feed_rate=0.646 â†’ feed_amt=442.16 g, temp_set=28.224, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.07\n",
      "Feed Cost:           0.54\n",
      "Heat Cost:           0.04\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.48\n",
      "\n",
      "\n",
      "--- Day 26 ---\n",
      "Raw-obs: biomass=7181.3 g, count=100, temp=30.29Â°C, DO=1.00 mg/L, UIA=0.181 mg/L\n",
      "Action: feed_rate=0.640 â†’ feed_amt=459.57 g, temp_set=31.717, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.12\n",
      "Feed Cost:           0.56\n",
      "Heat Cost:           0.05\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.50\n",
      "\n",
      "\n",
      "--- Day 27 ---\n",
      "Raw-obs: biomass=7523.0 g, count=100, temp=30.22Â°C, DO=1.00 mg/L, UIA=0.186 mg/L\n",
      "Action: feed_rate=0.635 â†’ feed_amt=478.04 g, temp_set=31.916, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.17\n",
      "Feed Cost:           0.58\n",
      "Heat Cost:           0.05\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.52\n",
      "\n",
      "\n",
      "--- Day 28 ---\n",
      "Raw-obs: biomass=7872.3 g, count=100, temp=30.17Â°C, DO=1.00 mg/L, UIA=0.192 mg/L\n",
      "Action: feed_rate=0.632 â†’ feed_amt=497.41 g, temp_set=31.963, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.23\n",
      "Feed Cost:           0.60\n",
      "Heat Cost:           0.04\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.57\n",
      "\n",
      "\n",
      "--- Day 29 ---\n",
      "Raw-obs: biomass=8232.7 g, count=100, temp=30.28Â°C, DO=1.00 mg/L, UIA=0.200 mg/L\n",
      "Action: feed_rate=0.632 â†’ feed_amt=520.43 g, temp_set=30.218, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.24\n",
      "Feed Cost:           0.63\n",
      "Heat Cost:           0.04\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.56\n",
      "\n",
      "\n",
      "--- Day 30 ---\n",
      "Raw-obs: biomass=8594.6 g, count=100, temp=30.01Â°C, DO=1.00 mg/L, UIA=0.205 mg/L\n",
      "Action: feed_rate=0.629 â†’ feed_amt=540.80 g, temp_set=32.468, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.35\n",
      "Feed Cost:           0.66\n",
      "Heat Cost:           0.04\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.63\n",
      "\n",
      "\n",
      "--- Day 31 ---\n",
      "Raw-obs: biomass=8973.0 g, count=100, temp=30.34Â°C, DO=1.00 mg/L, UIA=0.215 mg/L\n",
      "Action: feed_rate=0.626 â†’ feed_amt=561.30 g, temp_set=28.504, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.33\n",
      "Feed Cost:           0.68\n",
      "Heat Cost:           0.03\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.61\n",
      "\n",
      "\n",
      "--- Day 32 ---\n",
      "Raw-obs: biomass=9348.9 g, count=100, temp=29.96Â°C, DO=1.00 mg/L, UIA=0.218 mg/L\n",
      "Action: feed_rate=0.619 â†’ feed_amt=578.42 g, temp_set=31.573, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.39\n",
      "Feed Cost:           0.70\n",
      "Heat Cost:           0.04\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.64\n",
      "\n",
      "\n",
      "--- Day 33 ---\n",
      "Raw-obs: biomass=9734.9 g, count=100, temp=30.02Â°C, DO=1.00 mg/L, UIA=0.224 mg/L\n",
      "Action: feed_rate=0.615 â†’ feed_amt=598.25 g, temp_set=30.565, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.41\n",
      "Feed Cost:           0.72\n",
      "Heat Cost:           0.03\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.65\n",
      "\n",
      "\n",
      "--- Day 34 ---\n",
      "Raw-obs: biomass=10124.2 g, count=100, temp=29.88Â°C, DO=1.00 mg/L, UIA=0.229 mg/L\n",
      "Action: feed_rate=0.609 â†’ feed_amt=616.82 g, temp_set=31.470, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.47\n",
      "Feed Cost:           0.74\n",
      "Heat Cost:           0.04\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.67\n",
      "\n",
      "\n",
      "--- Day 35 ---\n",
      "Raw-obs: biomass=10522.3 g, count=100, temp=29.92Â°C, DO=1.00 mg/L, UIA=0.235 mg/L\n",
      "Action: feed_rate=0.606 â†’ feed_amt=638.09 g, temp_set=30.727, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.51\n",
      "Feed Cost:           0.77\n",
      "Heat Cost:           0.04\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.69\n",
      "\n",
      "\n",
      "--- Day 36 ---\n",
      "Raw-obs: biomass=10926.9 g, count=100, temp=29.89Â°C, DO=1.00 mg/L, UIA=0.241 mg/L\n",
      "Action: feed_rate=0.603 â†’ feed_amt=658.58 g, temp_set=30.504, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.50\n",
      "Feed Cost:           0.79\n",
      "Heat Cost:           0.04\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.65\n",
      "\n",
      "\n",
      "--- Day 37 ---\n",
      "Raw-obs: biomass=11329.8 g, count=100, temp=29.67Â°C, DO=1.00 mg/L, UIA=0.244 mg/L\n",
      "Action: feed_rate=0.596 â†’ feed_amt=675.19 g, temp_set=32.236, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.61\n",
      "Feed Cost:           0.81\n",
      "Heat Cost:           0.06\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.73\n",
      "\n",
      "\n",
      "--- Day 38 ---\n",
      "Raw-obs: biomass=11751.4 g, count=100, temp=29.98Â°C, DO=1.00 mg/L, UIA=0.254 mg/L\n",
      "Action: feed_rate=0.597 â†’ feed_amt=701.48 g, temp_set=28.984, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.59\n",
      "Feed Cost:           0.84\n",
      "Heat Cost:           0.03\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.71\n",
      "\n",
      "\n",
      "--- Day 39 ---\n",
      "Raw-obs: biomass=12169.9 g, count=100, temp=29.73Â°C, DO=1.00 mg/L, UIA=0.258 mg/L\n",
      "Action: feed_rate=0.590 â†’ feed_amt=717.67 g, temp_set=30.773, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.60\n",
      "Feed Cost:           0.86\n",
      "Heat Cost:           0.04\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.69\n",
      "\n",
      "\n",
      "--- Day 40 ---\n",
      "Raw-obs: biomass=12589.4 g, count=100, temp=29.62Â°C, DO=1.00 mg/L, UIA=0.262 mg/L\n",
      "Action: feed_rate=0.582 â†’ feed_amt=732.17 g, temp_set=31.481, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.66\n",
      "Feed Cost:           0.88\n",
      "Heat Cost:           0.04\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.73\n",
      "\n",
      "\n",
      "--- Day 41 ---\n",
      "Raw-obs: biomass=13018.4 g, count=100, temp=29.70Â°C, DO=1.00 mg/L, UIA=0.267 mg/L\n",
      "Action: feed_rate=0.575 â†’ feed_amt=748.51 g, temp_set=30.292, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.65\n",
      "Feed Cost:           0.90\n",
      "Heat Cost:           0.04\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.70\n",
      "\n",
      "\n",
      "--- Day 42 ---\n",
      "Raw-obs: biomass=13446.6 g, count=100, temp=29.57Â°C, DO=1.00 mg/L, UIA=0.270 mg/L\n",
      "Action: feed_rate=0.566 â†’ feed_amt=761.32 g, temp_set=31.114, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.71\n",
      "Feed Cost:           0.91\n",
      "Heat Cost:           0.04\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.75\n",
      "\n",
      "\n",
      "--- Day 43 ---\n",
      "Raw-obs: biomass=13884.1 g, count=100, temp=29.67Â°C, DO=1.00 mg/L, UIA=0.275 mg/L\n",
      "Action: feed_rate=0.560 â†’ feed_amt=777.27 g, temp_set=29.849, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.67\n",
      "Feed Cost:           0.93\n",
      "Heat Cost:           0.03\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.70\n",
      "\n",
      "\n",
      "--- Day 44 ---\n",
      "Raw-obs: biomass=14314.7 g, count=100, temp=29.45Â°C, DO=1.00 mg/L, UIA=0.276 mg/L\n",
      "Action: feed_rate=0.553 â†’ feed_amt=791.59 g, temp_set=31.619, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.82\n",
      "Feed Cost:           0.95\n",
      "Heat Cost:           0.04\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.82\n",
      "\n",
      "\n",
      "--- Day 45 ---\n",
      "Raw-obs: biomass=14768.9 g, count=100, temp=29.83Â°C, DO=1.00 mg/L, UIA=0.286 mg/L\n",
      "Action: feed_rate=0.546 â†’ feed_amt=806.27 g, temp_set=27.784, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.74\n",
      "Feed Cost:           0.96\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.74\n",
      "\n",
      "\n",
      "--- Day 46 ---\n",
      "Raw-obs: biomass=15211.2 g, count=100, temp=29.55Â°C, DO=1.00 mg/L, UIA=0.287 mg/L\n",
      "Action: feed_rate=0.537 â†’ feed_amt=816.81 g, temp_set=29.835, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.65\n",
      "Feed Cost:           0.97\n",
      "Heat Cost:           0.04\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.62\n",
      "\n",
      "\n",
      "--- Day 47 ---\n",
      "Raw-obs: biomass=15638.8 g, count=100, temp=29.24Â°C, DO=1.00 mg/L, UIA=0.284 mg/L\n",
      "Action: feed_rate=0.535 â†’ feed_amt=836.65 g, temp_set=32.695, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.91\n",
      "Feed Cost:           1.00\n",
      "Heat Cost:           0.06\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.84\n",
      "\n",
      "\n",
      "--- Day 48 ---\n",
      "Raw-obs: biomass=16107.8 g, count=100, temp=29.89Â°C, DO=1.00 mg/L, UIA=0.299 mg/L\n",
      "Action: feed_rate=0.516 â†’ feed_amt=831.39 g, temp_set=26.953, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.78\n",
      "Feed Cost:           0.99\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.76\n",
      "\n",
      "\n",
      "--- Day 49 ---\n",
      "Raw-obs: biomass=16555.9 g, count=100, temp=29.64Â°C, DO=1.00 mg/L, UIA=0.296 mg/L\n",
      "Action: feed_rate=0.517 â†’ feed_amt=855.37 g, temp_set=28.340, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.76\n",
      "Feed Cost:           1.02\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.70\n",
      "\n",
      "\n",
      "--- Day 50 ---\n",
      "Raw-obs: biomass=17001.0 g, count=100, temp=29.42Â°C, DO=1.00 mg/L, UIA=0.297 mg/L\n",
      "Action: feed_rate=0.511 â†’ feed_amt=869.34 g, temp_set=29.892, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.72\n",
      "Feed Cost:           1.04\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.64\n",
      "\n",
      "\n",
      "--- Day 51 ---\n",
      "Raw-obs: biomass=17439.0 g, count=100, temp=29.26Â°C, DO=1.00 mg/L, UIA=0.298 mg/L\n",
      "Action: feed_rate=0.507 â†’ feed_amt=884.92 g, temp_set=31.188, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.84\n",
      "Feed Cost:           1.05\n",
      "Heat Cost:           0.05\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.73\n",
      "\n",
      "\n",
      "--- Day 52 ---\n",
      "Raw-obs: biomass=17896.9 g, count=100, temp=29.53Â°C, DO=1.00 mg/L, UIA=0.306 mg/L\n",
      "Action: feed_rate=0.497 â†’ feed_amt=889.03 g, temp_set=28.418, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.71\n",
      "Feed Cost:           1.06\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.62\n",
      "\n",
      "\n",
      "--- Day 53 ---\n",
      "Raw-obs: biomass=18333.3 g, count=100, temp=29.26Â°C, DO=1.00 mg/L, UIA=0.304 mg/L\n",
      "Action: feed_rate=0.496 â†’ feed_amt=909.35 g, temp_set=30.656, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.77\n",
      "Feed Cost:           1.08\n",
      "Heat Cost:           0.04\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.64\n",
      "\n",
      "\n",
      "--- Day 54 ---\n",
      "Raw-obs: biomass=18780.7 g, count=100, temp=29.33Â°C, DO=1.00 mg/L, UIA=0.309 mg/L\n",
      "Action: feed_rate=0.489 â†’ feed_amt=918.00 g, temp_set=29.620, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.69\n",
      "Feed Cost:           1.09\n",
      "Heat Cost:           0.03\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.56\n",
      "\n",
      "\n",
      "--- Day 55 ---\n",
      "Raw-obs: biomass=19214.6 g, count=100, temp=29.16Â°C, DO=1.00 mg/L, UIA=0.309 mg/L\n",
      "Action: feed_rate=0.488 â†’ feed_amt=936.80 g, temp_set=31.058, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.80\n",
      "Feed Cost:           1.11\n",
      "Heat Cost:           0.04\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.64\n",
      "\n",
      "\n",
      "--- Day 56 ---\n",
      "Raw-obs: biomass=19666.8 g, count=100, temp=29.37Â°C, DO=1.00 mg/L, UIA=0.317 mg/L\n",
      "Action: feed_rate=0.474 â†’ feed_amt=932.66 g, temp_set=28.860, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.60\n",
      "Feed Cost:           1.11\n",
      "Heat Cost:           0.03\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.46\n",
      "\n",
      "\n",
      "--- Day 57 ---\n",
      "Raw-obs: biomass=20086.7 g, count=100, temp=29.03Â°C, DO=1.00 mg/L, UIA=0.311 mg/L\n",
      "Action: feed_rate=0.480 â†’ feed_amt=964.60 g, temp_set=31.902, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.86\n",
      "Feed Cost:           1.15\n",
      "Heat Cost:           0.04\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.66\n",
      "\n",
      "\n",
      "--- Day 58 ---\n",
      "Raw-obs: biomass=20548.0 g, count=100, temp=29.46Â°C, DO=1.00 mg/L, UIA=0.325 mg/L\n",
      "Action: feed_rate=0.456 â†’ feed_amt=936.57 g, temp_set=27.906, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.61\n",
      "Feed Cost:           1.11\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.47\n",
      "\n",
      "\n",
      "--- Day 59 ---\n",
      "Raw-obs: biomass=20969.4 g, count=100, temp=29.22Â°C, DO=1.00 mg/L, UIA=0.317 mg/L\n",
      "Action: feed_rate=0.466 â†’ feed_amt=977.23 g, temp_set=29.724, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.69\n",
      "Feed Cost:           1.16\n",
      "Heat Cost:           0.04\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.49\n",
      "\n",
      "\n",
      "--- Day 60 ---\n",
      "Raw-obs: biomass=21403.5 g, count=100, temp=29.14Â°C, DO=1.00 mg/L, UIA=0.322 mg/L\n",
      "Action: feed_rate=0.462 â†’ feed_amt=988.66 g, temp_set=29.973, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.68\n",
      "Feed Cost:           1.17\n",
      "Heat Cost:           0.04\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.46\n",
      "\n",
      "\n",
      "--- Day 61 ---\n",
      "Raw-obs: biomass=21835.8 g, count=100, temp=29.14Â°C, DO=1.00 mg/L, UIA=0.326 mg/L\n",
      "Action: feed_rate=0.455 â†’ feed_amt=993.08 g, temp_set=29.742, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.63\n",
      "Feed Cost:           1.18\n",
      "Heat Cost:           0.03\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.41\n",
      "\n",
      "\n",
      "--- Day 62 ---\n",
      "Raw-obs: biomass=22260.1 g, count=100, temp=29.09Â°C, DO=1.00 mg/L, UIA=0.327 mg/L\n",
      "Action: feed_rate=0.452 â†’ feed_amt=1006.08 g, temp_set=29.986, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.65\n",
      "Feed Cost:           1.19\n",
      "Heat Cost:           0.04\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.41\n",
      "\n",
      "\n",
      "--- Day 63 ---\n",
      "Raw-obs: biomass=22687.3 g, count=100, temp=29.12Â°C, DO=1.00 mg/L, UIA=0.330 mg/L\n",
      "Action: feed_rate=0.444 â†’ feed_amt=1006.44 g, temp_set=29.593, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.58\n",
      "Feed Cost:           1.19\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.35\n",
      "\n",
      "\n",
      "--- Day 64 ---\n",
      "Raw-obs: biomass=23103.3 g, count=100, temp=29.06Â°C, DO=1.00 mg/L, UIA=0.329 mg/L\n",
      "Action: feed_rate=0.442 â†’ feed_amt=1022.05 g, temp_set=29.983, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.64\n",
      "Feed Cost:           1.21\n",
      "Heat Cost:           0.04\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.38\n",
      "\n",
      "\n",
      "--- Day 65 ---\n",
      "Raw-obs: biomass=23528.3 g, count=100, temp=29.16Â°C, DO=1.00 mg/L, UIA=0.334 mg/L\n",
      "Action: feed_rate=0.430 â†’ feed_amt=1011.70 g, temp_set=29.102, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.46\n",
      "Feed Cost:           1.19\n",
      "Heat Cost:           0.03\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.22\n",
      "\n",
      "\n",
      "--- Day 66 ---\n",
      "Raw-obs: biomass=23924.8 g, count=100, temp=28.95Â°C, DO=1.00 mg/L, UIA=0.329 mg/L\n",
      "Action: feed_rate=0.438 â†’ feed_amt=1047.01 g, temp_set=30.843, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.69\n",
      "Feed Cost:           1.24\n",
      "Heat Cost:           0.04\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.41\n",
      "\n",
      "\n",
      "--- Day 67 ---\n",
      "Raw-obs: biomass=24359.1 g, count=100, temp=29.27Â°C, DO=1.00 mg/L, UIA=0.341 mg/L\n",
      "Action: feed_rate=0.411 â†’ feed_amt=1000.20 g, temp_set=28.032, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.36\n",
      "Feed Cost:           1.18\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.16\n",
      "\n",
      "\n",
      "--- Day 68 ---\n",
      "Raw-obs: biomass=24740.2 g, count=100, temp=29.03Â°C, DO=1.00 mg/L, UIA=0.329 mg/L\n",
      "Action: feed_rate=0.427 â†’ feed_amt=1055.43 g, temp_set=30.035, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.54\n",
      "Feed Cost:           1.25\n",
      "Heat Cost:           0.04\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.25\n",
      "\n",
      "\n",
      "--- Day 69 ---\n",
      "Raw-obs: biomass=25150.6 g, count=100, temp=29.04Â°C, DO=1.00 mg/L, UIA=0.339 mg/L\n",
      "Action: feed_rate=0.415 â†’ feed_amt=1044.31 g, temp_set=29.518, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.38\n",
      "Feed Cost:           1.23\n",
      "Heat Cost:           0.03\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.11\n",
      "\n",
      "\n",
      "--- Day 70 ---\n",
      "Raw-obs: biomass=25535.2 g, count=100, temp=28.90Â°C, DO=1.00 mg/L, UIA=0.335 mg/L\n",
      "Action: feed_rate=0.420 â†’ feed_amt=1072.34 g, temp_set=30.591, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.55\n",
      "Feed Cost:           1.27\n",
      "Heat Cost:           0.03\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.24\n",
      "\n",
      "\n",
      "--- Day 71 ---\n",
      "Raw-obs: biomass=25946.5 g, count=100, temp=29.13Â°C, DO=1.00 mg/L, UIA=0.345 mg/L\n",
      "Action: feed_rate=0.398 â†’ feed_amt=1033.52 g, temp_set=28.599, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.31\n",
      "Feed Cost:           1.22\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.05\n",
      "\n",
      "\n",
      "--- Day 72 ---\n",
      "Raw-obs: biomass=26318.4 g, count=100, temp=29.01Â°C, DO=1.00 mg/L, UIA=0.336 mg/L\n",
      "Action: feed_rate=0.406 â†’ feed_amt=1068.88 g, temp_set=29.707, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.40\n",
      "Feed Cost:           1.26\n",
      "Heat Cost:           0.03\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.10\n",
      "\n",
      "\n",
      "--- Day 73 ---\n",
      "Raw-obs: biomass=26706.1 g, count=100, temp=29.00Â°C, DO=1.00 mg/L, UIA=0.341 mg/L\n",
      "Action: feed_rate=0.399 â†’ feed_amt=1065.20 g, temp_set=29.509, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.32\n",
      "Feed Cost:           1.25\n",
      "Heat Cost:           0.03\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.02\n",
      "\n",
      "\n",
      "--- Day 74 ---\n",
      "Raw-obs: biomass=27080.2 g, count=100, temp=28.95Â°C, DO=1.00 mg/L, UIA=0.341 mg/L\n",
      "Action: feed_rate=0.398 â†’ feed_amt=1077.39 g, temp_set=29.848, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.36\n",
      "Feed Cost:           1.27\n",
      "Heat Cost:           0.03\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.05\n",
      "\n",
      "\n",
      "--- Day 75 ---\n",
      "Raw-obs: biomass=27461.2 g, count=100, temp=29.04Â°C, DO=1.00 mg/L, UIA=0.345 mg/L\n",
      "Action: feed_rate=0.387 â†’ feed_amt=1063.44 g, temp_set=29.064, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.18\n",
      "Feed Cost:           1.25\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.90\n",
      "\n",
      "\n",
      "--- Day 76 ---\n",
      "Raw-obs: biomass=27812.0 g, count=100, temp=28.82Â°C, DO=1.00 mg/L, UIA=0.338 mg/L\n",
      "Action: feed_rate=0.400 â†’ feed_amt=1112.39 g, temp_set=30.801, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.42\n",
      "Feed Cost:           1.31\n",
      "Heat Cost:           0.03\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        1.07\n",
      "\n",
      "\n",
      "--- Day 77 ---\n",
      "Raw-obs: biomass=28202.7 g, count=100, temp=29.06Â°C, DO=1.00 mg/L, UIA=0.352 mg/L\n",
      "Action: feed_rate=0.374 â†’ feed_amt=1054.30 g, temp_set=28.565, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.13\n",
      "Feed Cost:           1.24\n",
      "Heat Cost:           0.03\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.86\n",
      "\n",
      "\n",
      "--- Day 78 ---\n",
      "Raw-obs: biomass=28546.8 g, count=100, temp=29.00Â°C, DO=1.00 mg/L, UIA=0.341 mg/L\n",
      "Action: feed_rate=0.380 â†’ feed_amt=1085.82 g, temp_set=29.353, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.18\n",
      "Feed Cost:           1.28\n",
      "Heat Cost:           0.03\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.86\n",
      "\n",
      "\n",
      "--- Day 79 ---\n",
      "Raw-obs: biomass=28898.2 g, count=100, temp=28.88Â°C, DO=1.00 mg/L, UIA=0.343 mg/L\n",
      "Action: feed_rate=0.381 â†’ feed_amt=1100.21 g, temp_set=30.021, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.22\n",
      "Feed Cost:           1.29\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.89\n",
      "\n",
      "\n",
      "--- Day 80 ---\n",
      "Raw-obs: biomass=29256.5 g, count=100, temp=28.96Â°C, DO=1.00 mg/L, UIA=0.348 mg/L\n",
      "Action: feed_rate=0.369 â†’ feed_amt=1080.67 g, temp_set=29.225, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.04\n",
      "Feed Cost:           1.27\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.74\n",
      "\n",
      "\n",
      "--- Day 81 ---\n",
      "Raw-obs: biomass=29585.7 g, count=100, temp=28.79Â°C, DO=1.00 mg/L, UIA=0.342 mg/L\n",
      "Action: feed_rate=0.377 â†’ feed_amt=1114.70 g, temp_set=30.573, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.25\n",
      "Feed Cost:           1.31\n",
      "Heat Cost:           0.04\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.89\n",
      "\n",
      "\n",
      "--- Day 82 ---\n",
      "Raw-obs: biomass=29947.9 g, count=100, temp=29.06Â°C, DO=1.00 mg/L, UIA=0.352 mg/L\n",
      "Action: feed_rate=0.356 â†’ feed_amt=1065.43 g, temp_set=28.361, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.96\n",
      "Feed Cost:           1.25\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.68\n",
      "\n",
      "\n",
      "--- Day 83 ---\n",
      "Raw-obs: biomass=30263.6 g, count=100, temp=28.89Â°C, DO=1.00 mg/L, UIA=0.341 mg/L\n",
      "Action: feed_rate=0.368 â†’ feed_amt=1113.81 g, temp_set=29.904, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.15\n",
      "Feed Cost:           1.31\n",
      "Heat Cost:           0.03\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.80\n",
      "\n",
      "\n",
      "--- Day 84 ---\n",
      "Raw-obs: biomass=30609.8 g, count=100, temp=28.98Â°C, DO=1.00 mg/L, UIA=0.350 mg/L\n",
      "Action: feed_rate=0.351 â†’ feed_amt=1074.69 g, temp_set=28.789, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.91\n",
      "Feed Cost:           1.26\n",
      "Heat Cost:           0.03\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.61\n",
      "\n",
      "\n",
      "--- Day 85 ---\n",
      "Raw-obs: biomass=30917.4 g, count=100, temp=28.83Â°C, DO=1.00 mg/L, UIA=0.341 mg/L\n",
      "Action: feed_rate=0.364 â†’ feed_amt=1123.95 g, temp_set=30.179, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.11\n",
      "Feed Cost:           1.32\n",
      "Heat Cost:           0.04\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.74\n",
      "\n",
      "\n",
      "--- Day 86 ---\n",
      "Raw-obs: biomass=31257.5 g, count=100, temp=28.97Â°C, DO=1.00 mg/L, UIA=0.352 mg/L\n",
      "Action: feed_rate=0.341 â†’ feed_amt=1065.44 g, temp_set=28.712, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.77\n",
      "Feed Cost:           1.25\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.50\n",
      "\n",
      "\n",
      "--- Day 87 ---\n",
      "Raw-obs: biomass=31543.5 g, count=100, temp=28.73Â°C, DO=1.00 mg/L, UIA=0.338 mg/L\n",
      "Action: feed_rate=0.363 â†’ feed_amt=1143.58 g, temp_set=31.146, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.16\n",
      "Feed Cost:           1.34\n",
      "Heat Cost:           0.05\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.76\n",
      "\n",
      "\n",
      "--- Day 88 ---\n",
      "Raw-obs: biomass=31892.6 g, count=100, temp=29.09Â°C, DO=1.00 mg/L, UIA=0.358 mg/L\n",
      "Action: feed_rate=0.327 â†’ feed_amt=1043.66 g, temp_set=27.777, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.71\n",
      "Feed Cost:           1.22\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.46\n",
      "\n",
      "\n",
      "--- Day 89 ---\n",
      "Raw-obs: biomass=32167.9 g, count=100, temp=28.90Â°C, DO=1.00 mg/L, UIA=0.338 mg/L\n",
      "Action: feed_rate=0.351 â†’ feed_amt=1127.67 g, temp_set=29.720, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.98\n",
      "Feed Cost:           1.32\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.63\n",
      "\n",
      "\n",
      "--- Day 90 ---\n",
      "Raw-obs: biomass=32487.8 g, count=100, temp=28.91Â°C, DO=1.00 mg/L, UIA=0.351 mg/L\n",
      "Action: feed_rate=0.330 â†’ feed_amt=1071.44 g, temp_set=28.993, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.70\n",
      "Feed Cost:           1.25\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.41\n",
      "\n",
      "\n",
      "--- Day 91 ---\n",
      "Raw-obs: biomass=32762.4 g, count=100, temp=28.77Â°C, DO=1.00 mg/L, UIA=0.339 mg/L\n",
      "Action: feed_rate=0.349 â†’ feed_amt=1143.73 g, temp_set=30.531, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.01\n",
      "Feed Cost:           1.34\n",
      "Heat Cost:           0.03\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.62\n",
      "\n",
      "\n",
      "--- Day 92 ---\n",
      "Raw-obs: biomass=33086.1 g, count=100, temp=28.99Â°C, DO=1.00 mg/L, UIA=0.356 mg/L\n",
      "Action: feed_rate=0.317 â†’ feed_amt=1047.36 g, temp_set=28.207, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.60\n",
      "Feed Cost:           1.23\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.34\n",
      "\n",
      "\n",
      "--- Day 93 ---\n",
      "Raw-obs: biomass=33344.3 g, count=100, temp=28.85Â°C, DO=1.00 mg/L, UIA=0.337 mg/L\n",
      "Action: feed_rate=0.344 â†’ feed_amt=1145.38 g, temp_set=30.002, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.94\n",
      "Feed Cost:           1.34\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.57\n",
      "\n",
      "\n",
      "--- Day 94 ---\n",
      "Raw-obs: biomass=33657.4 g, count=100, temp=28.94Â°C, DO=1.00 mg/L, UIA=0.354 mg/L\n",
      "Action: feed_rate=0.312 â†’ feed_amt=1050.54 g, temp_set=28.489, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.53\n",
      "Feed Cost:           1.23\n",
      "Heat Cost:           0.00\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.28\n",
      "\n",
      "\n",
      "--- Day 95 ---\n",
      "Raw-obs: biomass=33904.1 g, count=100, temp=28.74Â°C, DO=1.00 mg/L, UIA=0.335 mg/L\n",
      "Action: feed_rate=0.344 â†’ feed_amt=1165.25 g, temp_set=30.961, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     2.02\n",
      "Feed Cost:           1.37\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.62\n",
      "\n",
      "\n",
      "--- Day 96 ---\n",
      "Raw-obs: biomass=34230.6 g, count=100, temp=29.14Â°C, DO=1.00 mg/L, UIA=0.362 mg/L\n",
      "Action: feed_rate=0.298 â†’ feed_amt=1020.16 g, temp_set=27.169, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.47\n",
      "Feed Cost:           1.19\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.25\n",
      "\n",
      "\n",
      "--- Day 97 ---\n",
      "Raw-obs: biomass=34468.5 g, count=100, temp=29.04Â°C, DO=1.00 mg/L, UIA=0.336 mg/L\n",
      "Action: feed_rate=0.323 â†’ feed_amt=1115.05 g, temp_set=28.676, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.75\n",
      "Feed Cost:           1.31\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.41\n",
      "\n",
      "\n",
      "--- Day 98 ---\n",
      "Raw-obs: biomass=34750.4 g, count=100, temp=28.94Â°C, DO=1.00 mg/L, UIA=0.348 mg/L\n",
      "Action: feed_rate=0.314 â†’ feed_amt=1090.23 g, temp_set=28.751, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.59\n",
      "Feed Cost:           1.28\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.28\n",
      "\n",
      "\n",
      "--- Day 99 ---\n",
      "Raw-obs: biomass=35006.4 g, count=100, temp=28.81Â°C, DO=1.00 mg/L, UIA=0.343 mg/L\n",
      "Action: feed_rate=0.320 â†’ feed_amt=1120.12 g, temp_set=29.745, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.70\n",
      "Feed Cost:           1.31\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.36\n",
      "\n",
      "\n",
      "--- Day 100 ---\n",
      "Raw-obs: biomass=35281.0 g, count=100, temp=28.93Â°C, DO=1.00 mg/L, UIA=0.350 mg/L\n",
      "Action: feed_rate=0.304 â†’ feed_amt=1073.78 g, temp_set=28.590, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.51\n",
      "Feed Cost:           1.26\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.23\n",
      "\n",
      "\n",
      "--- Day 101 ---\n",
      "Raw-obs: biomass=35524.9 g, count=100, temp=28.86Â°C, DO=1.00 mg/L, UIA=0.341 mg/L\n",
      "Action: feed_rate=0.319 â†’ feed_amt=1132.70 g, temp_set=29.507, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.67\n",
      "Feed Cost:           1.33\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.32\n",
      "\n",
      "\n",
      "--- Day 102 ---\n",
      "Raw-obs: biomass=35794.5 g, count=100, temp=28.85Â°C, DO=1.00 mg/L, UIA=0.351 mg/L\n",
      "Action: feed_rate=0.297 â†’ feed_amt=1064.72 g, temp_set=28.906, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.42\n",
      "Feed Cost:           1.24\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.14\n",
      "\n",
      "\n",
      "--- Day 103 ---\n",
      "Raw-obs: biomass=36024.2 g, count=100, temp=28.79Â°C, DO=1.00 mg/L, UIA=0.338 mg/L\n",
      "Action: feed_rate=0.320 â†’ feed_amt=1153.29 g, temp_set=30.067, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.74\n",
      "Feed Cost:           1.35\n",
      "Heat Cost:           0.03\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.35\n",
      "\n",
      "\n",
      "--- Day 104 ---\n",
      "Raw-obs: biomass=36305.1 g, count=100, temp=29.00Â°C, DO=1.00 mg/L, UIA=0.357 mg/L\n",
      "Action: feed_rate=0.284 â†’ feed_amt=1032.49 g, temp_set=27.819, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.30\n",
      "Feed Cost:           1.21\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.07\n",
      "\n",
      "\n",
      "--- Day 105 ---\n",
      "Raw-obs: biomass=36514.4 g, count=100, temp=28.81Â°C, DO=1.00 mg/L, UIA=0.333 mg/L\n",
      "Action: feed_rate=0.318 â†’ feed_amt=1159.77 g, temp_set=30.252, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.73\n",
      "Feed Cost:           1.36\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.34\n",
      "\n",
      "\n",
      "--- Day 106 ---\n",
      "Raw-obs: biomass=36794.0 g, count=100, temp=29.02Â°C, DO=1.00 mg/L, UIA=0.358 mg/L\n",
      "Action: feed_rate=0.279 â†’ feed_amt=1028.06 g, temp_set=27.650, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.29\n",
      "Feed Cost:           1.20\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.07\n",
      "\n",
      "\n",
      "--- Day 107 ---\n",
      "Raw-obs: biomass=37001.3 g, count=100, temp=28.93Â°C, DO=1.00 mg/L, UIA=0.334 mg/L\n",
      "Action: feed_rate=0.305 â†’ feed_amt=1130.12 g, temp_set=29.153, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.55\n",
      "Feed Cost:           1.32\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.19\n",
      "\n",
      "\n",
      "--- Day 108 ---\n",
      "Raw-obs: biomass=37250.5 g, count=100, temp=28.83Â°C, DO=1.00 mg/L, UIA=0.348 mg/L\n",
      "Action: feed_rate=0.289 â†’ feed_amt=1076.55 g, temp_set=29.058, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.37\n",
      "Feed Cost:           1.26\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.08\n",
      "\n",
      "\n",
      "--- Day 109 ---\n",
      "Raw-obs: biomass=37471.9 g, count=100, temp=28.86Â°C, DO=1.00 mg/L, UIA=0.341 mg/L\n",
      "Action: feed_rate=0.301 â†’ feed_amt=1126.87 g, temp_set=29.301, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.49\n",
      "Feed Cost:           1.32\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.14\n",
      "\n",
      "\n",
      "--- Day 110 ---\n",
      "Raw-obs: biomass=37711.9 g, count=100, temp=28.82Â°C, DO=1.00 mg/L, UIA=0.349 mg/L\n",
      "Action: feed_rate=0.284 â†’ feed_amt=1070.44 g, temp_set=28.997, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.28\n",
      "Feed Cost:           1.25\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.00\n",
      "\n",
      "\n",
      "--- Day 111 ---\n",
      "Raw-obs: biomass=37918.7 g, count=100, temp=28.72Â°C, DO=1.00 mg/L, UIA=0.337 mg/L\n",
      "Action: feed_rate=0.302 â†’ feed_amt=1145.26 g, temp_set=30.456, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.58\n",
      "Feed Cost:           1.34\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.21\n",
      "\n",
      "\n",
      "--- Day 112 ---\n",
      "Raw-obs: biomass=38173.5 g, count=100, temp=29.06Â°C, DO=1.00 mg/L, UIA=0.356 mg/L\n",
      "Action: feed_rate=0.271 â†’ feed_amt=1033.02 g, temp_set=27.423, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.21\n",
      "Feed Cost:           1.21\n",
      "Heat Cost:           0.00\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.01\n",
      "\n",
      "\n",
      "--- Day 113 ---\n",
      "Raw-obs: biomass=38367.8 g, count=100, temp=28.92Â°C, DO=1.00 mg/L, UIA=0.335 mg/L\n",
      "Action: feed_rate=0.293 â†’ feed_amt=1125.84 g, temp_set=29.053, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.43\n",
      "Feed Cost:           1.31\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.08\n",
      "\n",
      "\n",
      "--- Day 114 ---\n",
      "Raw-obs: biomass=38598.6 g, count=100, temp=28.84Â°C, DO=1.00 mg/L, UIA=0.348 mg/L\n",
      "Action: feed_rate=0.278 â†’ feed_amt=1074.13 g, temp_set=28.903, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.24\n",
      "Feed Cost:           1.25\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.04\n",
      "\n",
      "\n",
      "--- Day 115 ---\n",
      "Raw-obs: biomass=38799.3 g, count=100, temp=28.75Â°C, DO=1.00 mg/L, UIA=0.338 mg/L\n",
      "Action: feed_rate=0.293 â†’ feed_amt=1138.11 g, temp_set=29.957, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.44\n",
      "Feed Cost:           1.33\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.09\n",
      "\n",
      "\n",
      "--- Day 116 ---\n",
      "Raw-obs: biomass=39032.2 g, count=100, temp=28.90Â°C, DO=1.00 mg/L, UIA=0.352 mg/L\n",
      "Action: feed_rate=0.267 â†’ feed_amt=1041.76 g, temp_set=28.294, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.15\n",
      "Feed Cost:           1.22\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.10\n",
      "\n",
      "\n",
      "--- Day 117 ---\n",
      "Raw-obs: biomass=39217.9 g, count=100, temp=28.82Â°C, DO=1.00 mg/L, UIA=0.334 mg/L\n",
      "Action: feed_rate=0.293 â†’ feed_amt=1147.38 g, temp_set=29.746, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.47\n",
      "Feed Cost:           1.34\n",
      "Heat Cost:           0.03\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.09\n",
      "\n",
      "\n",
      "--- Day 118 ---\n",
      "Raw-obs: biomass=39455.2 g, count=100, temp=29.00Â°C, DO=1.00 mg/L, UIA=0.355 mg/L\n",
      "Action: feed_rate=0.261 â†’ feed_amt=1028.88 g, temp_set=27.651, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.12\n",
      "Feed Cost:           1.20\n",
      "Heat Cost:           0.00\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.09\n",
      "\n",
      "\n",
      "--- Day 119 ---\n",
      "Raw-obs: biomass=39635.5 g, count=100, temp=28.92Â°C, DO=1.00 mg/L, UIA=0.334 mg/L\n",
      "Action: feed_rate=0.283 â†’ feed_amt=1121.16 g, temp_set=28.948, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.32\n",
      "Feed Cost:           1.31\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.01\n",
      "\n",
      "\n",
      "--- Day 120 ---\n",
      "Raw-obs: biomass=39849.1 g, count=100, temp=28.82Â°C, DO=1.00 mg/L, UIA=0.346 mg/L\n",
      "Action: feed_rate=0.270 â†’ feed_amt=1077.07 g, temp_set=28.967, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.19\n",
      "Feed Cost:           1.26\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.10\n",
      "\n",
      "\n",
      "--- Day 121 ---\n",
      "Raw-obs: biomass=40040.6 g, count=100, temp=28.81Â°C, DO=1.00 mg/L, UIA=0.339 mg/L\n",
      "Action: feed_rate=0.280 â†’ feed_amt=1122.15 g, temp_set=29.385, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.32\n",
      "Feed Cost:           1.31\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.03\n",
      "\n",
      "\n",
      "--- Day 122 ---\n",
      "Raw-obs: biomass=40252.9 g, count=100, temp=28.91Â°C, DO=1.00 mg/L, UIA=0.349 mg/L\n",
      "Action: feed_rate=0.261 â†’ feed_amt=1052.17 g, temp_set=28.268, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.10\n",
      "Feed Cost:           1.23\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.15\n",
      "\n",
      "\n",
      "--- Day 123 ---\n",
      "Raw-obs: biomass=40431.0 g, count=100, temp=28.82Â°C, DO=1.00 mg/L, UIA=0.335 mg/L\n",
      "Action: feed_rate=0.282 â†’ feed_amt=1138.80 g, temp_set=29.513, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.33\n",
      "Feed Cost:           1.33\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.03\n",
      "\n",
      "\n",
      "--- Day 124 ---\n",
      "Raw-obs: biomass=40645.1 g, count=100, temp=28.88Â°C, DO=1.00 mg/L, UIA=0.351 mg/L\n",
      "Action: feed_rate=0.255 â†’ feed_amt=1035.87 g, temp_set=28.266, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.02\n",
      "Feed Cost:           1.21\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.21\n",
      "\n",
      "\n",
      "--- Day 125 ---\n",
      "Raw-obs: biomass=40809.4 g, count=100, temp=28.71Â°C, DO=1.00 mg/L, UIA=0.330 mg/L\n",
      "Action: feed_rate=0.284 â†’ feed_amt=1158.71 g, temp_set=30.724, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.40\n",
      "Feed Cost:           1.35\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        0.02\n",
      "\n",
      "\n",
      "--- Day 126 ---\n",
      "Raw-obs: biomass=41035.5 g, count=100, temp=29.05Â°C, DO=1.00 mg/L, UIA=0.357 mg/L\n",
      "Action: feed_rate=0.245 â†’ feed_amt=1004.03 g, temp_set=27.160, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.98\n",
      "Feed Cost:           1.17\n",
      "Heat Cost:           0.00\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.21\n",
      "\n",
      "\n",
      "--- Day 127 ---\n",
      "Raw-obs: biomass=41192.8 g, count=100, temp=28.95Â°C, DO=1.00 mg/L, UIA=0.329 mg/L\n",
      "Action: feed_rate=0.271 â†’ feed_amt=1115.39 g, temp_set=28.805, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.22\n",
      "Feed Cost:           1.30\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.11\n",
      "\n",
      "\n",
      "--- Day 128 ---\n",
      "Raw-obs: biomass=41389.6 g, count=100, temp=28.85Â°C, DO=1.00 mg/L, UIA=0.344 mg/L\n",
      "Action: feed_rate=0.260 â†’ feed_amt=1075.19 g, temp_set=28.721, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.08\n",
      "Feed Cost:           1.25\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.21\n",
      "\n",
      "\n",
      "--- Day 129 ---\n",
      "Raw-obs: biomass=41563.5 g, count=100, temp=28.76Â°C, DO=1.00 mg/L, UIA=0.338 mg/L\n",
      "Action: feed_rate=0.270 â†’ feed_amt=1122.07 g, temp_set=29.649, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.21\n",
      "Feed Cost:           1.31\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.13\n",
      "\n",
      "\n",
      "--- Day 130 ---\n",
      "Raw-obs: biomass=41758.5 g, count=100, temp=28.88Â°C, DO=1.00 mg/L, UIA=0.348 mg/L\n",
      "Action: feed_rate=0.251 â†’ feed_amt=1046.54 g, temp_set=28.325, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.99\n",
      "Feed Cost:           1.22\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.26\n",
      "\n",
      "\n",
      "--- Day 131 ---\n",
      "Raw-obs: biomass=41918.1 g, count=100, temp=28.74Â°C, DO=1.00 mg/L, UIA=0.332 mg/L\n",
      "Action: feed_rate=0.273 â†’ feed_amt=1144.37 g, temp_set=30.213, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.28\n",
      "Feed Cost:           1.34\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.09\n",
      "\n",
      "\n",
      "--- Day 132 ---\n",
      "Raw-obs: biomass=42124.7 g, count=100, temp=29.03Â°C, DO=1.00 mg/L, UIA=0.354 mg/L\n",
      "Action: feed_rate=0.240 â†’ feed_amt=1011.23 g, temp_set=27.295, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.91\n",
      "Feed Cost:           1.18\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.29\n",
      "\n",
      "\n",
      "--- Day 133 ---\n",
      "Raw-obs: biomass=42272.0 g, count=100, temp=28.83Â°C, DO=1.00 mg/L, UIA=0.328 mg/L\n",
      "Action: feed_rate=0.268 â†’ feed_amt=1130.83 g, temp_set=29.722, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.23\n",
      "Feed Cost:           1.32\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.11\n",
      "\n",
      "\n",
      "--- Day 134 ---\n",
      "Raw-obs: biomass=42471.1 g, count=100, temp=29.05Â°C, DO=1.00 mg/L, UIA=0.351 mg/L\n",
      "Action: feed_rate=0.243 â†’ feed_amt=1031.33 g, temp_set=27.364, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.97\n",
      "Feed Cost:           1.20\n",
      "Heat Cost:           0.00\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.25\n",
      "\n",
      "\n",
      "--- Day 135 ---\n",
      "Raw-obs: biomass=42627.1 g, count=100, temp=28.97Â°C, DO=1.00 mg/L, UIA=0.334 mg/L\n",
      "Action: feed_rate=0.255 â†’ feed_amt=1085.15 g, temp_set=28.322, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.08\n",
      "Feed Cost:           1.27\n",
      "Heat Cost:           0.00\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.20\n",
      "\n",
      "\n",
      "--- Day 136 ---\n",
      "Raw-obs: biomass=42802.0 g, count=100, temp=28.95Â°C, DO=1.00 mg/L, UIA=0.341 mg/L\n",
      "Action: feed_rate=0.250 â†’ feed_amt=1070.10 g, temp_set=28.169, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.03\n",
      "Feed Cost:           1.25\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.25\n",
      "\n",
      "\n",
      "--- Day 137 ---\n",
      "Raw-obs: biomass=42967.9 g, count=100, temp=28.92Â°C, DO=1.00 mg/L, UIA=0.339 mg/L\n",
      "Action: feed_rate=0.251 â†’ feed_amt=1080.58 g, temp_set=28.406, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.01\n",
      "Feed Cost:           1.26\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.29\n",
      "\n",
      "\n",
      "--- Day 138 ---\n",
      "Raw-obs: biomass=43130.0 g, count=100, temp=28.75Â°C, DO=1.00 mg/L, UIA=0.337 mg/L\n",
      "Action: feed_rate=0.257 â†’ feed_amt=1108.14 g, temp_set=29.506, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.08\n",
      "Feed Cost:           1.29\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.23\n",
      "\n",
      "\n",
      "--- Day 139 ---\n",
      "Raw-obs: biomass=43304.1 g, count=100, temp=28.86Â°C, DO=1.00 mg/L, UIA=0.345 mg/L\n",
      "Action: feed_rate=0.243 â†’ feed_amt=1054.17 g, temp_set=28.443, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.92\n",
      "Feed Cost:           1.23\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.33\n",
      "\n",
      "\n",
      "--- Day 140 ---\n",
      "Raw-obs: biomass=43452.7 g, count=100, temp=28.71Â°C, DO=1.00 mg/L, UIA=0.333 mg/L\n",
      "Action: feed_rate=0.260 â†’ feed_amt=1129.34 g, temp_set=30.232, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.13\n",
      "Feed Cost:           1.32\n",
      "Heat Cost:           0.03\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.23\n",
      "\n",
      "\n",
      "--- Day 141 ---\n",
      "Raw-obs: biomass=43635.0 g, count=100, temp=28.95Â°C, DO=1.00 mg/L, UIA=0.350 mg/L\n",
      "Action: feed_rate=0.233 â†’ feed_amt=1018.47 g, temp_set=27.729, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.85\n",
      "Feed Cost:           1.19\n",
      "Heat Cost:           0.00\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.36\n",
      "\n",
      "\n",
      "--- Day 142 ---\n",
      "Raw-obs: biomass=43771.6 g, count=100, temp=28.77Â°C, DO=1.00 mg/L, UIA=0.327 mg/L\n",
      "Action: feed_rate=0.258 â†’ feed_amt=1127.86 g, temp_set=30.092, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.14\n",
      "Feed Cost:           1.31\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.20\n",
      "\n",
      "\n",
      "--- Day 143 ---\n",
      "Raw-obs: biomass=43955.5 g, count=100, temp=29.08Â°C, DO=1.00 mg/L, UIA=0.351 mg/L\n",
      "Action: feed_rate=0.232 â†’ feed_amt=1017.93 g, temp_set=27.125, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.88\n",
      "Feed Cost:           1.19\n",
      "Heat Cost:           0.00\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.32\n",
      "\n",
      "\n",
      "--- Day 144 ---\n",
      "Raw-obs: biomass=44096.7 g, count=100, temp=29.02Â°C, DO=1.00 mg/L, UIA=0.332 mg/L\n",
      "Action: feed_rate=0.242 â†’ feed_amt=1068.10 g, temp_set=28.007, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.97\n",
      "Feed Cost:           1.24\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.30\n",
      "\n",
      "\n",
      "--- Day 145 ---\n",
      "Raw-obs: biomass=44252.5 g, count=100, temp=28.93Â°C, DO=1.00 mg/L, UIA=0.337 mg/L\n",
      "Action: feed_rate=0.242 â†’ feed_amt=1070.89 g, temp_set=28.307, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.94\n",
      "Feed Cost:           1.25\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.34\n",
      "\n",
      "\n",
      "--- Day 146 ---\n",
      "Raw-obs: biomass=44403.9 g, count=100, temp=28.83Â°C, DO=1.00 mg/L, UIA=0.337 mg/L\n",
      "Action: feed_rate=0.247 â†’ feed_amt=1096.33 g, temp_set=28.944, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.96\n",
      "Feed Cost:           1.28\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.34\n",
      "\n",
      "\n",
      "--- Day 147 ---\n",
      "Raw-obs: biomass=44558.6 g, count=100, temp=28.74Â°C, DO=1.00 mg/L, UIA=0.340 mg/L\n",
      "Action: feed_rate=0.242 â†’ feed_amt=1076.11 g, temp_set=29.276, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.90\n",
      "Feed Cost:           1.25\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.38\n",
      "\n",
      "\n",
      "--- Day 148 ---\n",
      "Raw-obs: biomass=44704.4 g, count=100, temp=28.71Â°C, DO=1.00 mg/L, UIA=0.336 mg/L\n",
      "Action: feed_rate=0.245 â†’ feed_amt=1096.64 g, temp_set=29.777, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.98\n",
      "Feed Cost:           1.28\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.33\n",
      "\n",
      "\n",
      "--- Day 149 ---\n",
      "Raw-obs: biomass=44863.1 g, count=100, temp=28.92Â°C, DO=1.00 mg/L, UIA=0.343 mg/L\n",
      "Action: feed_rate=0.234 â†’ feed_amt=1047.97 g, temp_set=28.077, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.85\n",
      "Feed Cost:           1.22\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.40\n",
      "\n",
      "\n",
      "--- Day 150 ---\n",
      "Raw-obs: biomass=44999.4 g, count=100, temp=28.75Â°C, DO=1.00 mg/L, UIA=0.332 mg/L\n",
      "Action: feed_rate=0.248 â†’ feed_amt=1113.94 g, temp_set=29.776, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.01\n",
      "Feed Cost:           1.30\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.32\n",
      "\n",
      "\n",
      "--- Day 151 ---\n",
      "Raw-obs: biomass=45162.2 g, count=100, temp=28.94Â°C, DO=1.00 mg/L, UIA=0.346 mg/L\n",
      "Action: feed_rate=0.227 â†’ feed_amt=1023.35 g, temp_set=27.811, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.78\n",
      "Feed Cost:           1.19\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.44\n",
      "\n",
      "\n",
      "--- Day 152 ---\n",
      "Raw-obs: biomass=45288.2 g, count=100, temp=28.72Â°C, DO=1.00 mg/L, UIA=0.327 mg/L\n",
      "Action: feed_rate=0.248 â†’ feed_amt=1120.91 g, temp_set=30.369, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     1.04\n",
      "Feed Cost:           1.31\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.30\n",
      "\n",
      "\n",
      "--- Day 153 ---\n",
      "Raw-obs: biomass=45455.6 g, count=100, temp=29.07Â°C, DO=1.00 mg/L, UIA=0.349 mg/L\n",
      "Action: feed_rate=0.221 â†’ feed_amt=1004.98 g, temp_set=27.068, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.78\n",
      "Feed Cost:           1.17\n",
      "Heat Cost:           0.00\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.40\n",
      "\n",
      "\n",
      "--- Day 154 ---\n",
      "Raw-obs: biomass=45582.0 g, count=100, temp=29.00Â°C, DO=1.00 mg/L, UIA=0.329 mg/L\n",
      "Action: feed_rate=0.233 â†’ feed_amt=1060.95 g, temp_set=28.063, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.89\n",
      "Feed Cost:           1.24\n",
      "Heat Cost:           0.00\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.36\n",
      "\n",
      "\n",
      "--- Day 155 ---\n",
      "Raw-obs: biomass=45725.1 g, count=100, temp=28.96Â°C, DO=1.00 mg/L, UIA=0.335 mg/L\n",
      "Action: feed_rate=0.230 â†’ feed_amt=1051.11 g, temp_set=28.053, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.83\n",
      "Feed Cost:           1.22\n",
      "Heat Cost:           0.00\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.40\n",
      "\n",
      "\n",
      "--- Day 156 ---\n",
      "Raw-obs: biomass=45859.6 g, count=100, temp=28.84Â°C, DO=1.00 mg/L, UIA=0.332 mg/L\n",
      "Action: feed_rate=0.238 â†’ feed_amt=1089.65 g, temp_set=28.949, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.90\n",
      "Feed Cost:           1.27\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.39\n",
      "\n",
      "\n",
      "--- Day 157 ---\n",
      "Raw-obs: biomass=46004.6 g, count=100, temp=28.84Â°C, DO=1.00 mg/L, UIA=0.339 mg/L\n",
      "Action: feed_rate=0.231 â†’ feed_amt=1060.77 g, temp_set=28.575, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.83\n",
      "Feed Cost:           1.24\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.44\n",
      "\n",
      "\n",
      "--- Day 158 ---\n",
      "Raw-obs: biomass=46137.9 g, count=100, temp=28.79Â°C, DO=1.00 mg/L, UIA=0.334 mg/L\n",
      "Action: feed_rate=0.237 â†’ feed_amt=1092.22 g, temp_set=29.150, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.88\n",
      "Feed Cost:           1.27\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.42\n",
      "\n",
      "\n",
      "--- Day 159 ---\n",
      "Raw-obs: biomass=46280.6 g, count=100, temp=28.82Â°C, DO=1.00 mg/L, UIA=0.340 mg/L\n",
      "Action: feed_rate=0.228 â†’ feed_amt=1053.39 g, temp_set=28.619, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.78\n",
      "Feed Cost:           1.23\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.47\n",
      "\n",
      "\n",
      "--- Day 160 ---\n",
      "Raw-obs: biomass=46405.8 g, count=100, temp=28.66Â°C, DO=1.00 mg/L, UIA=0.330 mg/L\n",
      "Action: feed_rate=0.238 â†’ feed_amt=1103.08 g, temp_set=30.425, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.94\n",
      "Feed Cost:           1.28\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.37\n",
      "\n",
      "\n",
      "--- Day 161 ---\n",
      "Raw-obs: biomass=46557.9 g, count=100, temp=29.09Â°C, DO=1.00 mg/L, UIA=0.346 mg/L\n",
      "Action: feed_rate=0.214 â†’ feed_amt=995.62 g, temp_set=27.004, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.73\n",
      "Feed Cost:           1.16\n",
      "Heat Cost:           0.00\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.44\n",
      "\n",
      "\n",
      "--- Day 162 ---\n",
      "Raw-obs: biomass=46675.2 g, count=100, temp=29.02Â°C, DO=1.00 mg/L, UIA=0.326 mg/L\n",
      "Action: feed_rate=0.225 â†’ feed_amt=1050.17 g, temp_set=27.953, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.80\n",
      "Feed Cost:           1.22\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.44\n",
      "\n",
      "\n",
      "--- Day 163 ---\n",
      "Raw-obs: biomass=46804.1 g, count=100, temp=28.85Â°C, DO=1.00 mg/L, UIA=0.330 mg/L\n",
      "Action: feed_rate=0.230 â†’ feed_amt=1078.27 g, temp_set=28.870, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.84\n",
      "Feed Cost:           1.26\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.44\n",
      "\n",
      "\n",
      "--- Day 164 ---\n",
      "Raw-obs: biomass=46938.9 g, count=100, temp=28.84Â°C, DO=1.00 mg/L, UIA=0.337 mg/L\n",
      "Action: feed_rate=0.227 â†’ feed_amt=1065.29 g, temp_set=28.657, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.78\n",
      "Feed Cost:           1.24\n",
      "Heat Cost:           0.00\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.47\n",
      "\n",
      "\n",
      "--- Day 165 ---\n",
      "Raw-obs: biomass=47065.3 g, count=100, temp=28.73Â°C, DO=1.00 mg/L, UIA=0.333 mg/L\n",
      "Action: feed_rate=0.230 â†’ feed_amt=1084.02 g, temp_set=29.547, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.82\n",
      "Feed Cost:           1.26\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.47\n",
      "\n",
      "\n",
      "--- Day 166 ---\n",
      "Raw-obs: biomass=47196.9 g, count=100, temp=28.76Â°C, DO=1.00 mg/L, UIA=0.337 mg/L\n",
      "Action: feed_rate=0.225 â†’ feed_amt=1063.63 g, temp_set=29.055, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.78\n",
      "Feed Cost:           1.24\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.49\n",
      "\n",
      "\n",
      "--- Day 167 ---\n",
      "Raw-obs: biomass=47322.2 g, count=100, temp=28.77Â°C, DO=1.00 mg/L, UIA=0.334 mg/L\n",
      "Action: feed_rate=0.229 â†’ feed_amt=1081.70 g, temp_set=29.204, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.80\n",
      "Feed Cost:           1.26\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.49\n",
      "\n",
      "\n",
      "--- Day 168 ---\n",
      "Raw-obs: biomass=47451.1 g, count=100, temp=28.75Â°C, DO=1.00 mg/L, UIA=0.336 mg/L\n",
      "Action: feed_rate=0.224 â†’ feed_amt=1063.28 g, temp_set=29.121, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.77\n",
      "Feed Cost:           1.24\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.51\n",
      "\n",
      "\n",
      "--- Day 169 ---\n",
      "Raw-obs: biomass=47574.8 g, count=100, temp=28.78Â°C, DO=1.00 mg/L, UIA=0.334 mg/L\n",
      "Action: feed_rate=0.226 â†’ feed_amt=1077.21 g, temp_set=29.114, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.77\n",
      "Feed Cost:           1.25\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.51\n",
      "\n",
      "\n",
      "--- Day 170 ---\n",
      "Raw-obs: biomass=47699.3 g, count=100, temp=28.70Â°C, DO=1.00 mg/L, UIA=0.335 mg/L\n",
      "Action: feed_rate=0.223 â†’ feed_amt=1065.72 g, temp_set=29.587, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.77\n",
      "Feed Cost:           1.24\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.50\n",
      "\n",
      "\n",
      "--- Day 171 ---\n",
      "Raw-obs: biomass=47822.8 g, count=100, temp=28.80Â°C, DO=1.00 mg/L, UIA=0.334 mg/L\n",
      "Action: feed_rate=0.224 â†’ feed_amt=1070.24 g, temp_set=28.907, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.75\n",
      "Feed Cost:           1.25\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.52\n",
      "\n",
      "\n",
      "--- Day 172 ---\n",
      "Raw-obs: biomass=47943.7 g, count=100, temp=28.69Â°C, DO=1.00 mg/L, UIA=0.333 mg/L\n",
      "Action: feed_rate=0.223 â†’ feed_amt=1069.95 g, temp_set=29.733, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.77\n",
      "Feed Cost:           1.25\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.50\n",
      "\n",
      "\n",
      "--- Day 173 ---\n",
      "Raw-obs: biomass=48068.5 g, count=100, temp=28.86Â°C, DO=1.00 mg/L, UIA=0.336 mg/L\n",
      "Action: feed_rate=0.218 â†’ feed_amt=1045.69 g, temp_set=28.410, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.70\n",
      "Feed Cost:           1.22\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.53\n",
      "\n",
      "\n",
      "--- Day 174 ---\n",
      "Raw-obs: biomass=48182.2 g, count=100, temp=28.72Â°C, DO=1.00 mg/L, UIA=0.329 mg/L\n",
      "Action: feed_rate=0.225 â†’ feed_amt=1084.54 g, temp_set=29.889, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.81\n",
      "Feed Cost:           1.26\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.49\n",
      "\n",
      "\n",
      "--- Day 175 ---\n",
      "Raw-obs: biomass=48312.8 g, count=100, temp=28.98Â°C, DO=1.00 mg/L, UIA=0.340 mg/L\n",
      "Action: feed_rate=0.208 â†’ feed_amt=1002.72 g, temp_set=27.571, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.66\n",
      "Feed Cost:           1.17\n",
      "Heat Cost:           0.00\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.52\n",
      "\n",
      "\n",
      "--- Day 176 ---\n",
      "Raw-obs: biomass=48418.6 g, count=100, temp=28.88Â°C, DO=1.00 mg/L, UIA=0.324 mg/L\n",
      "Action: feed_rate=0.219 â†’ feed_amt=1058.55 g, temp_set=28.857, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.71\n",
      "Feed Cost:           1.23\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.54\n",
      "\n",
      "\n",
      "--- Day 177 ---\n",
      "Raw-obs: biomass=48533.4 g, count=100, temp=28.68Â°C, DO=1.00 mg/L, UIA=0.328 mg/L\n",
      "Action: feed_rate=0.224 â†’ feed_amt=1087.37 g, temp_set=30.239, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.81\n",
      "Feed Cost:           1.27\n",
      "Heat Cost:           0.02\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.49\n",
      "\n",
      "\n",
      "--- Day 178 ---\n",
      "Raw-obs: biomass=48663.4 g, count=100, temp=29.02Â°C, DO=1.00 mg/L, UIA=0.341 mg/L\n",
      "Action: feed_rate=0.203 â†’ feed_amt=988.72 g, temp_set=27.293, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.62\n",
      "Feed Cost:           1.15\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.55\n",
      "\n",
      "\n",
      "--- Day 179 ---\n",
      "Raw-obs: biomass=48764.2 g, count=100, temp=28.89Â°C, DO=1.00 mg/L, UIA=0.322 mg/L\n",
      "Action: feed_rate=0.216 â†’ feed_amt=1053.94 g, temp_set=28.867, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.71\n",
      "Feed Cost:           1.23\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.54\n",
      "\n",
      "\n",
      "--- Day 180 ---\n",
      "Raw-obs: biomass=48878.3 g, count=100, temp=28.76Â°C, DO=1.00 mg/L, UIA=0.329 mg/L\n",
      "Action: feed_rate=0.219 â†’ feed_amt=1068.71 g, temp_set=29.490, aeration_rate=1.00 mg/L\n",
      "\n",
      "Reward Breakdown:\n",
      "Fish Value Gain:     0.74\n",
      "Feed Cost:           1.24\n",
      "Heat Cost:           0.01\n",
      "Oxygenation Cost:    0.01\n",
      "â†’ Net Reward:        -0.52\n",
      "\n",
      "\n",
      "=== Episode Summary ===\n",
      "Total Fish Value Gain:  294.97\n",
      "Total Feed Cost:        190.22\n",
      "Total Heat Cost:        4.76\n",
      "Total Oxygen Cost:      2.25\n",
      "Total Net Reward:       97.75\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from utils.calculation import Calculation\n",
    "\n",
    "# Reset environment\n",
    "obs, _ = env.reset()\n",
    "terminated = False\n",
    "truncated = False\n",
    "\n",
    "# Accumulators\n",
    "total_reward         = 0.0\n",
    "total_value_gain     = 0.0\n",
    "total_feed_cost      = 0.0\n",
    "total_heat_cost      = 0.0\n",
    "total_oxygen_cost    = 0.0\n",
    "\n",
    "print(\"Action space:\", env.action_space)\n",
    "\n",
    "while not (terminated or truncated):\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    raw = env.denormalize(obs)\n",
    "    biomass, fish_count, temp, do_level, uia = raw\n",
    "    feed_amount = Calculation.compute_feed_weight(action[0], biomass)\n",
    "\n",
    "    print(f\"\"\"\\n--- Day {env.day + 1} ---\n",
    "Raw-obs: biomass={biomass:.1f} g, count={fish_count:.0f}, temp={temp:.2f}Â°C, DO={do_level:.2f} mg/L, UIA={uia:.3f} mg/L\n",
    "Action: feed_rate={action[0]:.3f} â†’ feed_amt={feed_amount:.2f} g, temp_set={action[1]:.3f}, aeration_rate={action[2]:.2f} mg/L\n",
    "\"\"\")\n",
    "\n",
    "    obs, reward, terminated, truncated, info = env.step(action)\n",
    "    total_reward      += reward\n",
    "    total_value_gain  += info['fish_value']\n",
    "    total_feed_cost   += info['feed_cost']\n",
    "    total_heat_cost   += info['heat_cost']\n",
    "    total_oxygen_cost += info['oxygenation_cost']\n",
    "\n",
    "    print(f\"\"\"Reward Breakdown:\n",
    "Fish Value Gain:     {info['fish_value']:.2f}\n",
    "Feed Cost:           {info['feed_cost']:.2f}\n",
    "Heat Cost:           {info['heat_cost']:.2f}\n",
    "Oxygenation Cost:    {info['oxygenation_cost']:.2f}\n",
    "â†’ Net Reward:        {info['reward']:.2f}\n",
    "\"\"\")\n",
    "\n",
    "    env.render()\n",
    "\n",
    "    if hasattr(env, 'exit_requested') and env.exit_requested:\n",
    "        break\n",
    "\n",
    "    time.sleep(0.01)\n",
    "\n",
    "env.close()\n",
    "\n",
    "# Final totals\n",
    "print(\"\\n=== Episode Summary ===\")\n",
    "print(f\"Total Fish Value Gain:  {total_value_gain:.2f}\")\n",
    "print(f\"Total Feed Cost:        {total_feed_cost:.2f}\")\n",
    "print(f\"Total Heat Cost:        {total_heat_cost:.2f}\")\n",
    "print(f\"Total Oxygen Cost:      {total_oxygen_cost:.2f}\")\n",
    "print(f\"Total Net Reward:       {total_reward:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
